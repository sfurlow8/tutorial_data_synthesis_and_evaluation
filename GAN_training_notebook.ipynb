{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0511634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# mount to my Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc9ecd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 24 17:15:26 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   32C    P0             44W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d9c300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "GPU: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available()) # should be true\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0)) # should be NVIDIA A100-SXM4-40GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "502f06ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run if you need to reclone\n",
    "!rm -r /content/tutorial_data_synthesis_and_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d33dc73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Cloning into 'tutorial_data_synthesis_and_evaluation'...\n",
      "remote: Enumerating objects: 218, done.\u001b[K\n",
      "remote: Counting objects: 100% (121/121), done.\u001b[K\n",
      "remote: Compressing objects: 100% (98/98), done.\u001b[K\n",
      "remote: Total 218 (delta 53), reused 66 (delta 20), pack-reused 97 (from 1)\u001b[K\n",
      "Receiving objects: 100% (218/218), 31.03 MiB | 15.97 MiB/s, done.\n",
      "Resolving deltas: 100% (106/106), done.\n",
      "/content/tutorial_data_synthesis_and_evaluation\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "!git clone https://github.com/sfurlow8/tutorial_data_synthesis_and_evaluation.git\n",
    "%cd tutorial_data_synthesis_and_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22d0301a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_list_only_diagnosis.npy\n",
      "mapping_tables\n",
      "min_max_log.npy\n",
      "normalized_testing_data.csv\n",
      "normalized_training_data.csv\n",
      "one_y_outcome.npy\n",
      "original_testing_data.csv\n",
      "original_training_data.csv\n",
      "patient_bmi_bp_dict.npy\n",
      "patient_concept_mat_df.csv\n",
      "patient_concept_mat_only_diagnosis.npy\n",
      "patient_diagnosis_dict.npy\n",
      "patient_ICD_diagnosis_final_dict.npy\n",
      "patient_phecode_diagnosis_final_dict.npy\n",
      "patient_prescriptions_dict.npy\n",
      "patient_prescriptions_ingr_rxcui_final_dict.npy\n",
      "patient_prescriptions_rxcui_final_dict.npy\n",
      "patient_procedures_hcpcs_dict.npy\n",
      "patient_procedures_icd_dict.npy\n",
      "patients_anchor_age_not_last_v_y.npy\n",
      "patients_dict_w_admission_n_die_inhosp.npy\n",
      "patients_dict_w_admission.npy\n",
      "patients_final_dict.npy\n",
      "patients_w_icd_diag_9_10.npy\n",
      "patients_w_icd_proc_9_10.npy\n",
      "preprocessed_training_data.csv\n",
      "rxnav_cache.json\n"
     ]
    }
   ],
   "source": [
    "!ls /content/drive/MyDrive/mimic_synthetic_data/Data/preprocessing/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab379544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2.0,>=1.26 (from -r requirements_colab.txt (line 6))\n",
      "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting scipy<1.14,>=1.11 (from -r requirements_colab.txt (line 7))\n",
      "  Using cached scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting pandas<2.3,>=2.0 (from -r requirements_colab.txt (line 8))\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib<3.10,>=3.8 (from -r requirements_colab.txt (line 9))\n",
      "  Using cached matplotlib-3.9.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting scikit-learn<1.6,>=1.3 (from -r requirements_colab.txt (line 10))\n",
      "  Using cached scikit_learn-1.5.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting lightgbm<4.7,>=4.0 (from -r requirements_colab.txt (line 13))\n",
      "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
      "Collecting joblib<2.0,>=1.2 (from -r requirements_colab.txt (line 14))\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting shap<0.46,>=0.42 (from -r requirements_colab.txt (line 15))\n",
      "  Using cached shap-0.45.1-cp312-cp312-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
      "Collecting requests<2.33,>=2.28 (from -r requirements_colab.txt (line 16))\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas<2.3,>=2.0->-r requirements_colab.txt (line 8))\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas<2.3,>=2.0->-r requirements_colab.txt (line 8))\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<2.3,>=2.0->-r requirements_colab.txt (line 8))\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib<3.10,>=3.8->-r requirements_colab.txt (line 9))\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib<3.10,>=3.8->-r requirements_colab.txt (line 9))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib<3.10,>=3.8->-r requirements_colab.txt (line 9))\n",
      "  Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib<3.10,>=3.8->-r requirements_colab.txt (line 9))\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting packaging>=20.0 (from matplotlib<3.10,>=3.8->-r requirements_colab.txt (line 9))\n",
      "  Downloading packaging-26.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib<3.10,>=3.8->-r requirements_colab.txt (line 9))\n",
      "  Downloading pillow-12.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib<3.10,>=3.8->-r requirements_colab.txt (line 9)) (2.4.7)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn<1.6,>=1.3->-r requirements_colab.txt (line 10))\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tqdm>=4.27.0 (from shap<0.46,>=0.42->-r requirements_colab.txt (line 15))\n",
      "  Downloading tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting slicer==0.0.8 (from shap<0.46,>=0.42->-r requirements_colab.txt (line 15))\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting numba (from shap<0.46,>=0.42->-r requirements_colab.txt (line 15))\n",
      "  Downloading numba-0.64.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.9 kB)\n",
      "Collecting cloudpickle (from shap<0.46,>=0.42->-r requirements_colab.txt (line 15))\n",
      "  Downloading cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<2.33,>=2.28->-r requirements_colab.txt (line 16))\n",
      "  Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<2.33,>=2.28->-r requirements_colab.txt (line 16))\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<2.33,>=2.28->-r requirements_colab.txt (line 16))\n",
      "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<2.33,>=2.28->-r requirements_colab.txt (line 16))\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas<2.3,>=2.0->-r requirements_colab.txt (line 8)) (1.16.0)\n",
      "Collecting llvmlite<0.47,>=0.46.0dev0 (from numba->shap<0.46,>=0.42->-r requirements_colab.txt (line 15))\n",
      "  Downloading llvmlite-0.46.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.0 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "Using cached scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
      "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m147.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hUsing cached matplotlib-3.9.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Using cached scikit_learn-1.5.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m125.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached shap-0.45.1-cp312-cp312-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (544 kB)\n",
      "Downloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.6/362.6 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m149.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-26.0-py3-none-any.whl (74 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-12.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.5/348.5 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
      "Downloading numba-0.64.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.46.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, urllib3, tzdata, tqdm, threadpoolctl, slicer, python-dateutil, pillow, packaging, numpy, llvmlite, kiwisolver, joblib, idna, fonttools, cycler, cloudpickle, charset_normalizer, certifi, scipy, requests, pandas, numba, contourpy, scikit-learn, matplotlib, lightgbm, shap\n",
      "Successfully installed certifi-2026.1.4 charset_normalizer-3.4.4 cloudpickle-3.1.2 contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 idna-3.11 joblib-1.5.3 kiwisolver-1.4.9 lightgbm-4.6.0 llvmlite-0.46.0 matplotlib-3.9.4 numba-0.64.0 numpy-1.26.4 packaging-26.0 pandas-2.2.3 pillow-12.1.1 python-dateutil-2.9.0.post0 pytz-2025.2 requests-2.32.5 scikit-learn-1.5.2 scipy-1.13.1 shap-0.45.1 slicer-0.0.8 threadpoolctl-3.6.0 tqdm-4.67.3 tzdata-2025.3 urllib3-2.6.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "69dc279d518d4260826fe910a6558909",
       "pip_warning": {
        "packages": [
         "PIL",
         "certifi",
         "cycler",
         "dateutil",
         "idna",
         "kiwisolver",
         "matplotlib",
         "mpl_toolkits",
         "numpy",
         "packaging",
         "requests",
         "scipy",
         "tqdm",
         "urllib3"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -r requirements_colab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52592ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall tensorflow -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ac3e8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==4.25.3\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 6.33.5\n",
      "    Uninstalling protobuf-6.33.5:\n",
      "      Successfully uninstalled protobuf-6.33.5\n",
      "Successfully installed protobuf-4.25.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "25f2cdf3d0304e1695ed2e1b69b3dbfc",
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.16.2\n",
      "  Downloading tensorflow-2.16.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.2) (2.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.2) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.2) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.2) (0.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.2) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.2) (3.15.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.2) (18.1.1)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.2)\n",
      "  Downloading ml_dtypes-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.2) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.2) (26.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.2) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.2) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.2) (82.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow==2.16.2) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.2) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.2) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.2) (2.1.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.2) (1.78.0)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.2)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.2) (3.13.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.2) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow==2.16.2) (0.46.3)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.0.0->tensorflow==2.16.2) (14.3.3)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.0.0->tensorflow==2.16.2) (0.1.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.0.0->tensorflow==2.16.2) (0.18.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (2026.1.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.2) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.2) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2) (0.1.2)\n",
      "Downloading tensorflow-2.16.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (590.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.8/590.8 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, tensorflow\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml_dtypes 0.5.4\n",
      "    Uninstalling ml_dtypes-0.5.4:\n",
      "      Successfully uninstalled ml_dtypes-0.5.4\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.20.0\n",
      "    Uninstalling tensorboard-2.20.0:\n",
      "      Successfully uninstalled tensorboard-2.20.0\n",
      "Successfully installed ml-dtypes-0.3.2 tensorboard-2.16.2 tensorflow-2.16.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "e03895022c1e4520aecb685725c1f76a",
       "pip_warning": {
        "packages": [
         "ml_dtypes"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==4.25.3\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "Successfully installed protobuf-4.25.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "e348b9bf47fb4b73b7bbbab1e171b0fa",
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install TensorFlow 2.16.2 (earliest stable version supporting Python 3.12)\n",
    "# Install compatible protobuf version first to avoid symbol mismatch errors\n",
    "!pip install \"protobuf==4.25.3\" --force-reinstall\n",
    "!pip install \"tensorflow==2.16.2\"\n",
    "!pip install \"protobuf==4.25.3\" --force-reinstall --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "701eef1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-24 17:16:12.773583: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-24 17:16:12.789672: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1771953372.809332    1491 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1771953372.815757    1491 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1771953372.830925    1491 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771953372.830948    1491 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771953372.830951    1491 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771953372.830954    1491 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2026-02-24 17:16:12.835441: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1771953398.025204    1491 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38477 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n",
      "training start\n",
      "2026-02-24 17:16:50.037881: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "epoch: 0, loss = -3732.422363, w = -9.530761, (10.91)\n",
      "2026-02-24 17:16:50.804398: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2026-02-24 17:16:52.226313: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2026-02-24 17:16:55.011020: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "epoch: 10, loss = -10.606796, w = 1.770962, (0.73)\n",
      "2026-02-24 17:17:00.750626: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "epoch: 20, loss = -0.081603, w = 4.037008, (0.70)\n",
      "epoch: 30, loss = 3.582345, w = 4.863697, (0.70)\n",
      "2026-02-24 17:17:11.933181: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "epoch: 40, loss = 3.347252, w = 4.079188, (0.69)\n",
      "epoch: 50, loss = 3.050121, w = 3.533548, (0.67)\n",
      "epoch: 60, loss = 2.749131, w = 3.108147, (0.71)\n",
      "2026-02-24 17:17:34.335082: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "epoch: 70, loss = 2.405540, w = 2.655049, (0.69)\n",
      "epoch: 80, loss = 2.153077, w = 2.343044, (0.67)\n",
      "epoch: 90, loss = 1.856215, w = 2.001939, (0.69)\n",
      "epoch: 100, loss = 1.719342, w = 1.835513, (0.72)\n",
      "epoch: 110, loss = 1.495283, w = 1.584323, (0.69)\n",
      "epoch: 120, loss = 1.270200, w = 1.338189, (0.70)\n",
      "2026-02-24 17:18:18.920136: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "epoch: 130, loss = 0.903628, w = 0.960510, (0.70)\n",
      "epoch: 140, loss = 0.850009, w = 0.919149, (0.74)\n",
      "epoch: 150, loss = 0.872455, w = 0.958233, (0.69)\n",
      "ckpt 150 saved with loss 0.872455\n",
      "epoch: 160, loss = 0.895658, w = 0.959177, (0.68)\n",
      "epoch: 170, loss = 0.893615, w = 0.951789, (0.68)\n",
      "epoch: 180, loss = 0.882244, w = 0.934609, (0.70)\n",
      "epoch: 190, loss = 0.871125, w = 0.924110, (0.71)\n",
      "epoch: 200, loss = 0.852276, w = 0.904604, (0.71)\n",
      "ckpt 200 saved with loss 0.852276\n",
      "epoch: 210, loss = 0.834351, w = 0.886280, (0.69)\n",
      "epoch: 220, loss = 0.818800, w = 0.870571, (0.71)\n",
      "epoch: 230, loss = 0.806299, w = 0.859549, (0.67)\n",
      "epoch: 240, loss = 0.799709, w = 0.852562, (0.69)\n",
      "epoch: 250, loss = 0.787528, w = 0.841825, (0.69)\n",
      "ckpt 250 saved with loss 0.787528\n",
      "2026-02-24 17:19:47.861799: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "epoch: 260, loss = 0.778991, w = 0.833831, (0.71)\n",
      "epoch: 270, loss = 0.766659, w = 0.821001, (0.69)\n",
      "epoch: 280, loss = 0.753953, w = 0.808050, (0.69)\n",
      "epoch: 290, loss = 0.743163, w = 0.796889, (0.69)\n",
      "epoch: 300, loss = 0.729700, w = 0.781115, (0.67)\n",
      "ckpt 300 saved with loss 0.729700\n",
      "epoch: 310, loss = 0.724049, w = 0.775056, (0.68)\n",
      "epoch: 320, loss = 0.715515, w = 0.765711, (0.70)\n",
      "epoch: 330, loss = 0.707443, w = 0.756013, (0.72)\n",
      "epoch: 340, loss = 0.699729, w = 0.747349, (0.71)\n",
      "epoch: 350, loss = 0.693903, w = 0.740487, (0.68)\n",
      "ckpt 350 saved with loss 0.693903\n",
      "epoch: 360, loss = 0.688428, w = 0.734051, (0.67)\n",
      "epoch: 370, loss = 0.682587, w = 0.727154, (0.68)\n",
      "epoch: 380, loss = 0.678396, w = 0.722552, (0.69)\n",
      "epoch: 390, loss = 0.671222, w = 0.715068, (0.69)\n",
      "epoch: 400, loss = 0.666044, w = 0.709724, (0.69)\n",
      "ckpt 400 saved with loss 0.666044\n",
      "epoch: 410, loss = 0.658814, w = 0.701826, (0.67)\n",
      "epoch: 420, loss = 0.651569, w = 0.694223, (0.68)\n",
      "epoch: 430, loss = 0.646822, w = 0.688837, (0.69)\n",
      "epoch: 440, loss = 0.641706, w = 0.682986, (0.67)\n",
      "epoch: 450, loss = 0.634402, w = 0.675178, (0.71)\n",
      "ckpt 450 saved with loss 0.634402\n",
      "epoch: 460, loss = 0.629623, w = 0.670011, (0.71)\n",
      "epoch: 470, loss = 0.623407, w = 0.663324, (0.71)\n",
      "epoch: 480, loss = 0.618539, w = 0.657701, (0.67)\n",
      "epoch: 490, loss = 0.612556, w = 0.651953, (0.69)\n",
      "epoch: 500, loss = 0.610429, w = 0.648905, (0.70)\n",
      "ckpt 500 saved with loss 0.610429\n",
      "epoch: 510, loss = 0.606795, w = 0.645283, (0.68)\n",
      "2026-02-24 17:22:44.926034: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "epoch: 520, loss = 0.603707, w = 0.641859, (0.68)\n",
      "epoch: 530, loss = 0.600994, w = 0.638800, (0.67)\n",
      "epoch: 540, loss = 0.598334, w = 0.635888, (0.69)\n",
      "epoch: 550, loss = 0.595583, w = 0.632613, (0.69)\n",
      "ckpt 550 saved with loss 0.595583\n",
      "epoch: 560, loss = 0.593146, w = 0.630266, (0.70)\n",
      "epoch: 570, loss = 0.591204, w = 0.627720, (0.67)\n",
      "epoch: 580, loss = 0.587252, w = 0.623531, (0.71)\n",
      "epoch: 590, loss = 0.585268, w = 0.621685, (0.69)\n",
      "epoch: 600, loss = 0.581514, w = 0.617567, (0.71)\n",
      "ckpt 600 saved with loss 0.581514\n",
      "epoch: 610, loss = 0.578458, w = 0.614904, (0.69)\n",
      "epoch: 620, loss = 0.573640, w = 0.610109, (0.68)\n",
      "epoch: 630, loss = 0.569475, w = 0.605139, (0.67)\n",
      "epoch: 640, loss = 0.568952, w = 0.604254, (0.70)\n",
      "epoch: 650, loss = 0.565723, w = 0.600985, (0.70)\n",
      "ckpt 650 saved with loss 0.565723\n",
      "epoch: 660, loss = 0.563353, w = 0.598435, (0.69)\n",
      "epoch: 670, loss = 0.560621, w = 0.595362, (0.67)\n",
      "epoch: 680, loss = 0.558182, w = 0.592937, (0.67)\n",
      "epoch: 690, loss = 0.555178, w = 0.589432, (0.69)\n",
      "epoch: 700, loss = 0.553356, w = 0.587602, (0.67)\n",
      "ckpt 700 saved with loss 0.553356\n",
      "epoch: 710, loss = 0.550151, w = 0.584526, (0.69)\n",
      "epoch: 720, loss = 0.547827, w = 0.581456, (0.72)\n",
      "epoch: 730, loss = 0.545452, w = 0.579214, (0.69)\n",
      "epoch: 740, loss = 0.543804, w = 0.577132, (0.69)\n",
      "epoch: 750, loss = 0.542324, w = 0.575208, (0.67)\n",
      "ckpt 750 saved with loss 0.542324\n",
      "epoch: 760, loss = 0.538842, w = 0.572090, (0.68)\n",
      "epoch: 770, loss = 0.537545, w = 0.570480, (0.67)\n",
      "epoch: 780, loss = 0.534806, w = 0.567555, (0.67)\n",
      "epoch: 790, loss = 0.532422, w = 0.565060, (0.68)\n",
      "epoch: 800, loss = 0.529965, w = 0.562492, (0.69)\n",
      "ckpt 800 saved with loss 0.529965\n",
      "epoch: 810, loss = 0.528565, w = 0.561034, (0.69)\n",
      "epoch: 820, loss = 0.526042, w = 0.558459, (0.67)\n",
      "epoch: 830, loss = 0.523992, w = 0.556399, (0.69)\n",
      "epoch: 840, loss = 0.522945, w = 0.554878, (0.72)\n",
      "epoch: 850, loss = 0.520772, w = 0.552634, (0.71)\n",
      "ckpt 850 saved with loss 0.520772\n",
      "epoch: 860, loss = 0.518740, w = 0.550663, (0.68)\n",
      "epoch: 870, loss = 0.515865, w = 0.547553, (0.69)\n",
      "epoch: 880, loss = 0.514162, w = 0.545457, (0.68)\n",
      "epoch: 890, loss = 0.511229, w = 0.542640, (0.69)\n",
      "epoch: 900, loss = 0.509347, w = 0.540573, (0.68)\n",
      "ckpt 900 saved with loss 0.509347\n",
      "epoch: 910, loss = 0.508716, w = 0.539744, (0.71)\n",
      "epoch: 920, loss = 0.507083, w = 0.538576, (0.71)\n",
      "epoch: 930, loss = 0.504367, w = 0.535689, (0.71)\n",
      "epoch: 940, loss = 0.502665, w = 0.534016, (0.71)\n",
      "epoch: 950, loss = 0.502618, w = 0.533338, (0.69)\n",
      "ckpt 950 saved with loss 0.502618\n",
      "epoch: 960, loss = 0.499479, w = 0.530659, (0.70)\n",
      "epoch: 970, loss = 0.498377, w = 0.529461, (0.70)\n",
      "epoch: 980, loss = 0.496549, w = 0.527406, (0.69)\n",
      "epoch: 990, loss = 0.495278, w = 0.525968, (0.70)\n",
      "epoch: 1000, loss = 0.493675, w = 0.524732, (0.74)\n",
      "ckpt 1000 saved with loss 0.493675\n",
      "epoch: 1010, loss = 0.492221, w = 0.522981, (0.70)\n",
      "epoch: 1020, loss = 0.490791, w = 0.521081, (0.69)\n",
      "2026-02-24 17:28:40.099107: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "epoch: 1030, loss = 0.489239, w = 0.519945, (0.71)\n",
      "epoch: 1040, loss = 0.487706, w = 0.518458, (0.71)\n",
      "epoch: 1050, loss = 0.487073, w = 0.517696, (0.69)\n",
      "ckpt 1050 saved with loss 0.487073\n",
      "epoch: 1060, loss = 0.485805, w = 0.515894, (0.67)\n",
      "epoch: 1070, loss = 0.484534, w = 0.515007, (0.67)\n",
      "epoch: 1080, loss = 0.483295, w = 0.513473, (0.73)\n",
      "epoch: 1090, loss = 0.482169, w = 0.512225, (0.71)\n",
      "epoch: 1100, loss = 0.481158, w = 0.510914, (0.71)\n",
      "ckpt 1100 saved with loss 0.481158\n",
      "epoch: 1110, loss = 0.479907, w = 0.509988, (0.71)\n",
      "epoch: 1120, loss = 0.478352, w = 0.508469, (0.68)\n",
      "epoch: 1130, loss = 0.477593, w = 0.507132, (0.68)\n",
      "epoch: 1140, loss = 0.477570, w = 0.507080, (0.68)\n",
      "epoch: 1150, loss = 0.475251, w = 0.505071, (0.70)\n",
      "ckpt 1150 saved with loss 0.475251\n",
      "epoch: 1160, loss = 0.474911, w = 0.504516, (0.67)\n",
      "epoch: 1170, loss = 0.473424, w = 0.502949, (0.68)\n",
      "epoch: 1180, loss = 0.472556, w = 0.502502, (0.71)\n",
      "epoch: 1190, loss = 0.471383, w = 0.500786, (0.67)\n",
      "epoch: 1200, loss = 0.470030, w = 0.499333, (0.71)\n",
      "ckpt 1200 saved with loss 0.470030\n",
      "epoch: 1210, loss = 0.469322, w = 0.498599, (0.70)\n",
      "epoch: 1220, loss = 0.468826, w = 0.497926, (0.72)\n",
      "epoch: 1230, loss = 0.468192, w = 0.497199, (0.68)\n",
      "epoch: 1240, loss = 0.467129, w = 0.496370, (0.68)\n",
      "epoch: 1250, loss = 0.467295, w = 0.496122, (0.67)\n",
      "ckpt 1250 saved with loss 0.467295\n",
      "epoch: 1260, loss = 0.465810, w = 0.494969, (0.68)\n",
      "epoch: 1270, loss = 0.465535, w = 0.494547, (0.68)\n",
      "epoch: 1280, loss = 0.465640, w = 0.494512, (0.69)\n",
      "epoch: 1290, loss = 0.464879, w = 0.493388, (0.67)\n",
      "epoch: 1300, loss = 0.464359, w = 0.493153, (0.69)\n",
      "ckpt 1300 saved with loss 0.464359\n",
      "epoch: 1310, loss = 0.464158, w = 0.492699, (0.69)\n",
      "epoch: 1320, loss = 0.463367, w = 0.492187, (0.69)\n",
      "epoch: 1330, loss = 0.462260, w = 0.490964, (0.72)\n",
      "epoch: 1340, loss = 0.462348, w = 0.491110, (0.69)\n",
      "epoch: 1350, loss = 0.461593, w = 0.490183, (0.70)\n",
      "ckpt 1350 saved with loss 0.461593\n",
      "epoch: 1360, loss = 0.460796, w = 0.489899, (0.69)\n",
      "epoch: 1370, loss = 0.460034, w = 0.489262, (0.68)\n",
      "epoch: 1380, loss = 0.460299, w = 0.488912, (0.70)\n",
      "epoch: 1390, loss = 0.460071, w = 0.489019, (0.69)\n",
      "epoch: 1400, loss = 0.459509, w = 0.488072, (0.69)\n",
      "ckpt 1400 saved with loss 0.459509\n",
      "epoch: 1410, loss = 0.459300, w = 0.488225, (0.67)\n",
      "epoch: 1420, loss = 0.459184, w = 0.487975, (0.69)\n",
      "epoch: 1430, loss = 0.458946, w = 0.488155, (0.69)\n",
      "epoch: 1440, loss = 0.458879, w = 0.487609, (0.71)\n",
      "epoch: 1450, loss = 0.458947, w = 0.487893, (0.68)\n",
      "ckpt 1450 saved with loss 0.458947\n",
      "epoch: 1460, loss = 0.459467, w = 0.487747, (0.68)\n",
      "epoch: 1470, loss = 0.457442, w = 0.486317, (0.67)\n",
      "epoch: 1480, loss = 0.457900, w = 0.486531, (0.71)\n",
      "epoch: 1490, loss = 0.457259, w = 0.485946, (0.67)\n",
      "epoch: 1500, loss = 0.456039, w = 0.484431, (0.69)\n",
      "ckpt 1500 saved with loss 0.456039\n",
      "epoch: 1510, loss = 0.455972, w = 0.484352, (0.69)\n",
      "epoch: 1520, loss = 0.456119, w = 0.484358, (0.67)\n",
      "epoch: 1530, loss = 0.455020, w = 0.483676, (0.71)\n",
      "epoch: 1540, loss = 0.455555, w = 0.484029, (0.68)\n",
      "epoch: 1550, loss = 0.454885, w = 0.483575, (0.67)\n",
      "ckpt 1550 saved with loss 0.454885\n",
      "epoch: 1560, loss = 0.454692, w = 0.483009, (0.69)\n",
      "epoch: 1570, loss = 0.454689, w = 0.483142, (0.67)\n",
      "epoch: 1580, loss = 0.453678, w = 0.482089, (0.66)\n",
      "epoch: 1590, loss = 0.451974, w = 0.480978, (0.68)\n",
      "epoch: 1600, loss = 0.451803, w = 0.480559, (0.69)\n",
      "ckpt 1600 saved with loss 0.451803\n",
      "epoch: 1610, loss = 0.451684, w = 0.480335, (0.67)\n",
      "epoch: 1620, loss = 0.452141, w = 0.480579, (0.68)\n",
      "epoch: 1630, loss = 0.451105, w = 0.479853, (0.69)\n",
      "epoch: 1640, loss = 0.450168, w = 0.479669, (0.67)\n",
      "epoch: 1650, loss = 0.450992, w = 0.479848, (0.67)\n",
      "ckpt 1650 saved with loss 0.450992\n",
      "epoch: 1660, loss = 0.450538, w = 0.479230, (0.69)\n",
      "epoch: 1670, loss = 0.449485, w = 0.478134, (0.68)\n",
      "epoch: 1680, loss = 0.450209, w = 0.478921, (0.68)\n",
      "epoch: 1690, loss = 0.448927, w = 0.477491, (0.68)\n",
      "epoch: 1700, loss = 0.449689, w = 0.477949, (0.68)\n",
      "ckpt 1700 saved with loss 0.449689\n",
      "epoch: 1710, loss = 0.448994, w = 0.477854, (0.68)\n",
      "epoch: 1720, loss = 0.449134, w = 0.477383, (0.69)\n",
      "epoch: 1730, loss = 0.447922, w = 0.476111, (0.69)\n",
      "epoch: 1740, loss = 0.447242, w = 0.475720, (0.69)\n",
      "epoch: 1750, loss = 0.446661, w = 0.475097, (0.67)\n",
      "ckpt 1750 saved with loss 0.446661\n",
      "epoch: 1760, loss = 0.446854, w = 0.475261, (0.68)\n",
      "epoch: 1770, loss = 0.446423, w = 0.475118, (0.69)\n",
      "epoch: 1780, loss = 0.445420, w = 0.474483, (0.69)\n",
      "epoch: 1790, loss = 0.445579, w = 0.474380, (0.67)\n",
      "epoch: 1800, loss = 0.444325, w = 0.472875, (0.68)\n",
      "ckpt 1800 saved with loss 0.444325\n",
      "epoch: 1810, loss = 0.444618, w = 0.472795, (0.69)\n",
      "epoch: 1820, loss = 0.444352, w = 0.473229, (0.67)\n",
      "epoch: 1830, loss = 0.443197, w = 0.471774, (0.69)\n",
      "epoch: 1840, loss = 0.442872, w = 0.471137, (0.69)\n",
      "epoch: 1850, loss = 0.442599, w = 0.471257, (0.67)\n",
      "ckpt 1850 saved with loss 0.442599\n",
      "epoch: 1860, loss = 0.443059, w = 0.470918, (0.69)\n",
      "epoch: 1870, loss = 0.442231, w = 0.470494, (0.68)\n",
      "epoch: 1880, loss = 0.440746, w = 0.469295, (0.69)\n",
      "epoch: 1890, loss = 0.442181, w = 0.470425, (0.69)\n",
      "epoch: 1900, loss = 0.441241, w = 0.469944, (0.67)\n",
      "ckpt 1900 saved with loss 0.441241\n",
      "epoch: 1910, loss = 0.440124, w = 0.469100, (0.67)\n",
      "epoch: 1920, loss = 0.439635, w = 0.468222, (0.68)\n",
      "epoch: 1930, loss = 0.439300, w = 0.468225, (0.68)\n",
      "epoch: 1940, loss = 0.438277, w = 0.467246, (0.67)\n",
      "epoch: 1950, loss = 0.438079, w = 0.466547, (0.69)\n",
      "ckpt 1950 saved with loss 0.438079\n",
      "epoch: 1960, loss = 0.438236, w = 0.467029, (0.69)\n",
      "epoch: 1970, loss = 0.438428, w = 0.466593, (0.67)\n",
      "epoch: 1980, loss = 0.438566, w = 0.467514, (0.68)\n",
      "epoch: 1990, loss = 0.435906, w = 0.464410, (0.67)\n",
      "epoch: 2000, loss = 0.436899, w = 0.465134, (0.67)\n",
      "ckpt 2000 saved with loss 0.436899\n",
      "epoch: 2010, loss = 0.436094, w = 0.464378, (0.69)\n",
      "epoch: 2020, loss = 0.435709, w = 0.464519, (0.66)\n",
      "epoch: 2030, loss = 0.435886, w = 0.463831, (0.70)\n",
      "epoch: 2040, loss = 0.434265, w = 0.463511, (0.67)\n",
      "2026-02-24 17:40:20.858365: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "epoch: 2050, loss = 0.435591, w = 0.463621, (0.68)\n",
      "ckpt 2050 saved with loss 0.435591\n",
      "epoch: 2060, loss = 0.434584, w = 0.463197, (0.67)\n",
      "epoch: 2070, loss = 0.433758, w = 0.461935, (0.67)\n",
      "epoch: 2080, loss = 0.430934, w = 0.459543, (0.68)\n",
      "epoch: 2090, loss = 0.431666, w = 0.459940, (0.67)\n",
      "epoch: 2100, loss = 0.431815, w = 0.460238, (0.68)\n",
      "ckpt 2100 saved with loss 0.431815\n",
      "epoch: 2110, loss = 0.431056, w = 0.458841, (0.68)\n",
      "epoch: 2120, loss = 0.430457, w = 0.458601, (0.67)\n",
      "epoch: 2130, loss = 0.429933, w = 0.457994, (0.69)\n",
      "epoch: 2140, loss = 0.430847, w = 0.459199, (0.69)\n",
      "epoch: 2150, loss = 0.428412, w = 0.456846, (0.67)\n",
      "ckpt 2150 saved with loss 0.428412\n",
      "epoch: 2160, loss = 0.429462, w = 0.457430, (0.68)\n",
      "epoch: 2170, loss = 0.427729, w = 0.455685, (0.68)\n",
      "epoch: 2180, loss = 0.428154, w = 0.456230, (0.66)\n",
      "epoch: 2190, loss = 0.429963, w = 0.457367, (0.68)\n",
      "epoch: 2200, loss = 0.428231, w = 0.456246, (0.69)\n",
      "ckpt 2200 saved with loss 0.428231\n",
      "epoch: 2210, loss = 0.427585, w = 0.456313, (0.67)\n",
      "epoch: 2220, loss = 0.427273, w = 0.455289, (0.69)\n",
      "epoch: 2230, loss = 0.426894, w = 0.455232, (0.67)\n",
      "epoch: 2240, loss = 0.426230, w = 0.454758, (0.68)\n",
      "epoch: 2250, loss = 0.426717, w = 0.455307, (0.66)\n",
      "ckpt 2250 saved with loss 0.426717\n",
      "epoch: 2260, loss = 0.426853, w = 0.454918, (0.69)\n",
      "epoch: 2270, loss = 0.425976, w = 0.453385, (0.69)\n",
      "epoch: 2280, loss = 0.425637, w = 0.453333, (0.68)\n",
      "epoch: 2290, loss = 0.425461, w = 0.453823, (0.67)\n",
      "epoch: 2300, loss = 0.425262, w = 0.453115, (0.66)\n",
      "ckpt 2300 saved with loss 0.425262\n",
      "epoch: 2310, loss = 0.424062, w = 0.452023, (0.68)\n",
      "epoch: 2320, loss = 0.424406, w = 0.452094, (0.67)\n",
      "epoch: 2330, loss = 0.424640, w = 0.452475, (0.68)\n",
      "epoch: 2340, loss = 0.423313, w = 0.452128, (0.67)\n",
      "epoch: 2350, loss = 0.424390, w = 0.451809, (0.67)\n",
      "ckpt 2350 saved with loss 0.424390\n",
      "epoch: 2360, loss = 0.422219, w = 0.450896, (0.66)\n",
      "epoch: 2370, loss = 0.424013, w = 0.452281, (0.67)\n",
      "epoch: 2380, loss = 0.423134, w = 0.451320, (0.67)\n",
      "epoch: 2390, loss = 0.422371, w = 0.450825, (0.67)\n",
      "epoch: 2400, loss = 0.421508, w = 0.450068, (0.66)\n",
      "ckpt 2400 saved with loss 0.421508\n",
      "epoch: 2410, loss = 0.422209, w = 0.450628, (0.67)\n",
      "epoch: 2420, loss = 0.423628, w = 0.452014, (0.68)\n",
      "epoch: 2430, loss = 0.422405, w = 0.451384, (0.68)\n",
      "epoch: 2440, loss = 0.422554, w = 0.449930, (0.68)\n",
      "epoch: 2450, loss = 0.422341, w = 0.451262, (0.69)\n",
      "epoch: 2460, loss = 0.421704, w = 0.449938, (0.67)\n",
      "epoch: 2470, loss = 0.422969, w = 0.451512, (0.69)\n",
      "epoch: 2480, loss = 0.421544, w = 0.450539, (0.69)\n",
      "epoch: 2490, loss = 0.421973, w = 0.450549, (0.67)\n",
      "epoch: 2500, loss = 0.420858, w = 0.448937, (0.69)\n",
      "ckpt 2500 saved with loss 0.420858\n",
      "epoch: 2510, loss = 0.421324, w = 0.449786, (0.66)\n",
      "epoch: 2520, loss = 0.422403, w = 0.449827, (0.67)\n",
      "epoch: 2530, loss = 0.423024, w = 0.450878, (0.67)\n",
      "epoch: 2540, loss = 0.420837, w = 0.449932, (0.69)\n",
      "epoch: 2550, loss = 0.420890, w = 0.449802, (0.67)\n",
      "epoch: 2560, loss = 0.419948, w = 0.448690, (0.68)\n",
      "epoch: 2570, loss = 0.420886, w = 0.449806, (0.68)\n",
      "epoch: 2580, loss = 0.421034, w = 0.449736, (0.68)\n",
      "epoch: 2590, loss = 0.421413, w = 0.450688, (0.67)\n",
      "epoch: 2600, loss = 0.422857, w = 0.451220, (0.69)\n",
      "epoch: 2610, loss = 0.423404, w = 0.451618, (0.69)\n",
      "epoch: 2620, loss = 0.422010, w = 0.450081, (0.67)\n",
      "epoch: 2630, loss = 0.421197, w = 0.449842, (0.69)\n",
      "epoch: 2640, loss = 0.421091, w = 0.449610, (0.70)\n",
      "epoch: 2650, loss = 0.420723, w = 0.448370, (0.67)\n",
      "ckpt 2650 saved with loss 0.420723\n",
      "epoch: 2660, loss = 0.421597, w = 0.450002, (0.68)\n",
      "epoch: 2670, loss = 0.421443, w = 0.450065, (0.67)\n",
      "epoch: 2680, loss = 0.420401, w = 0.448714, (0.68)\n",
      "epoch: 2690, loss = 0.420149, w = 0.448459, (0.67)\n",
      "epoch: 2700, loss = 0.420179, w = 0.448179, (0.67)\n",
      "ckpt 2700 saved with loss 0.420179\n",
      "epoch: 2710, loss = 0.420753, w = 0.448527, (0.66)\n",
      "epoch: 2720, loss = 0.420526, w = 0.448311, (0.67)\n",
      "epoch: 2730, loss = 0.418681, w = 0.447267, (0.69)\n",
      "epoch: 2740, loss = 0.419325, w = 0.447027, (0.67)\n",
      "epoch: 2750, loss = 0.418258, w = 0.446462, (0.67)\n",
      "ckpt 2750 saved with loss 0.418258\n",
      "epoch: 2760, loss = 0.417978, w = 0.445988, (0.69)\n",
      "epoch: 2770, loss = 0.418037, w = 0.446564, (0.68)\n",
      "epoch: 2780, loss = 0.417395, w = 0.445514, (0.66)\n",
      "epoch: 2790, loss = 0.417429, w = 0.445493, (0.67)\n",
      "epoch: 2800, loss = 0.418043, w = 0.445864, (0.68)\n",
      "ckpt 2800 saved with loss 0.418043\n",
      "epoch: 2810, loss = 0.416942, w = 0.445091, (0.66)\n",
      "epoch: 2820, loss = 0.417006, w = 0.445212, (0.69)\n",
      "epoch: 2830, loss = 0.416689, w = 0.444732, (0.66)\n",
      "epoch: 2840, loss = 0.416097, w = 0.443862, (0.68)\n",
      "epoch: 2850, loss = 0.416412, w = 0.444631, (0.67)\n",
      "ckpt 2850 saved with loss 0.416412\n",
      "epoch: 2860, loss = 0.415643, w = 0.444102, (0.69)\n",
      "epoch: 2870, loss = 0.415457, w = 0.443756, (0.67)\n",
      "epoch: 2880, loss = 0.414481, w = 0.442384, (0.69)\n",
      "epoch: 2890, loss = 0.413613, w = 0.441954, (0.69)\n",
      "epoch: 2900, loss = 0.414823, w = 0.442576, (0.67)\n",
      "ckpt 2900 saved with loss 0.414823\n",
      "epoch: 2910, loss = 0.413699, w = 0.441962, (0.70)\n",
      "epoch: 2920, loss = 0.413543, w = 0.442470, (0.68)\n",
      "epoch: 2930, loss = 0.413241, w = 0.441329, (0.66)\n",
      "epoch: 2940, loss = 0.412204, w = 0.441129, (0.69)\n",
      "epoch: 2950, loss = 0.413084, w = 0.442387, (0.67)\n",
      "ckpt 2950 saved with loss 0.413084\n",
      "epoch: 2960, loss = 0.411587, w = 0.439897, (0.67)\n",
      "epoch: 2970, loss = 0.412061, w = 0.440787, (0.67)\n",
      "epoch: 2980, loss = 0.411771, w = 0.440189, (0.69)\n",
      "epoch: 2990, loss = 0.411589, w = 0.439779, (0.66)\n",
      "epoch: 3000, loss = 0.411707, w = 0.440641, (0.67)\n",
      "ckpt 3000 saved with loss 0.411707\n",
      "epoch: 3010, loss = 0.411000, w = 0.439058, (0.66)\n",
      "epoch: 3020, loss = 0.410837, w = 0.439151, (0.67)\n",
      "epoch: 3030, loss = 0.409862, w = 0.437865, (0.66)\n",
      "epoch: 3040, loss = 0.409615, w = 0.438169, (0.67)\n",
      "epoch: 3050, loss = 0.409654, w = 0.438138, (0.68)\n",
      "ckpt 3050 saved with loss 0.409654\n",
      "epoch: 3060, loss = 0.408508, w = 0.436896, (0.69)\n",
      "epoch: 3070, loss = 0.407895, w = 0.436714, (0.70)\n",
      "epoch: 3080, loss = 0.409702, w = 0.437802, (0.68)\n",
      "epoch: 3090, loss = 0.407085, w = 0.435444, (0.66)\n",
      "epoch: 3100, loss = 0.406952, w = 0.435334, (0.68)\n",
      "ckpt 3100 saved with loss 0.406952\n",
      "epoch: 3110, loss = 0.406798, w = 0.435097, (0.69)\n",
      "epoch: 3120, loss = 0.406956, w = 0.435030, (0.66)\n",
      "epoch: 3130, loss = 0.406539, w = 0.434995, (0.66)\n",
      "epoch: 3140, loss = 0.407227, w = 0.435203, (0.67)\n",
      "epoch: 3150, loss = 0.405840, w = 0.434347, (0.68)\n",
      "ckpt 3150 saved with loss 0.405840\n",
      "epoch: 3160, loss = 0.404423, w = 0.433525, (0.67)\n",
      "epoch: 3170, loss = 0.403945, w = 0.433579, (0.68)\n",
      "epoch: 3180, loss = 0.406454, w = 0.434635, (0.69)\n",
      "epoch: 3190, loss = 0.404820, w = 0.433485, (0.69)\n",
      "epoch: 3200, loss = 0.404335, w = 0.433219, (0.69)\n",
      "ckpt 3200 saved with loss 0.404335\n",
      "epoch: 3210, loss = 0.404734, w = 0.433414, (0.68)\n",
      "epoch: 3220, loss = 0.403483, w = 0.431874, (0.68)\n",
      "epoch: 3230, loss = 0.403026, w = 0.431595, (0.67)\n",
      "epoch: 3240, loss = 0.401716, w = 0.431020, (0.67)\n",
      "epoch: 3250, loss = 0.402721, w = 0.432275, (0.70)\n",
      "ckpt 3250 saved with loss 0.402721\n",
      "epoch: 3260, loss = 0.401922, w = 0.430263, (0.67)\n",
      "epoch: 3270, loss = 0.402670, w = 0.431553, (0.66)\n",
      "epoch: 3280, loss = 0.401818, w = 0.430242, (0.67)\n",
      "epoch: 3290, loss = 0.402824, w = 0.431299, (0.67)\n",
      "epoch: 3300, loss = 0.402286, w = 0.430712, (0.67)\n",
      "ckpt 3300 saved with loss 0.402286\n",
      "epoch: 3310, loss = 0.400629, w = 0.429353, (0.66)\n",
      "epoch: 3320, loss = 0.401506, w = 0.430815, (0.67)\n",
      "epoch: 3330, loss = 0.400636, w = 0.428592, (0.67)\n",
      "epoch: 3340, loss = 0.398812, w = 0.428972, (0.69)\n",
      "epoch: 3350, loss = 0.398627, w = 0.428230, (0.68)\n",
      "ckpt 3350 saved with loss 0.398627\n",
      "epoch: 3360, loss = 0.398407, w = 0.427922, (0.67)\n",
      "epoch: 3370, loss = 0.399459, w = 0.427868, (0.68)\n",
      "epoch: 3380, loss = 0.399685, w = 0.429306, (0.67)\n",
      "epoch: 3390, loss = 0.398803, w = 0.428056, (0.67)\n",
      "epoch: 3400, loss = 0.398283, w = 0.426187, (0.66)\n",
      "ckpt 3400 saved with loss 0.398283\n",
      "epoch: 3410, loss = 0.398201, w = 0.426946, (0.67)\n",
      "epoch: 3420, loss = 0.396253, w = 0.424441, (0.68)\n",
      "epoch: 3430, loss = 0.396671, w = 0.425471, (0.68)\n",
      "epoch: 3440, loss = 0.397704, w = 0.425996, (0.69)\n",
      "epoch: 3450, loss = 0.397795, w = 0.426664, (0.68)\n",
      "ckpt 3450 saved with loss 0.397795\n",
      "epoch: 3460, loss = 0.398305, w = 0.426404, (0.67)\n",
      "epoch: 3470, loss = 0.395311, w = 0.423556, (0.68)\n",
      "epoch: 3480, loss = 0.397646, w = 0.425195, (0.68)\n",
      "epoch: 3490, loss = 0.395481, w = 0.424205, (0.67)\n",
      "epoch: 3500, loss = 0.395616, w = 0.424405, (0.70)\n",
      "ckpt 3500 saved with loss 0.395616\n",
      "epoch: 3510, loss = 0.394879, w = 0.423564, (0.67)\n",
      "epoch: 3520, loss = 0.392600, w = 0.420415, (0.68)\n",
      "epoch: 3530, loss = 0.393659, w = 0.421721, (0.67)\n",
      "epoch: 3540, loss = 0.394976, w = 0.422031, (0.68)\n",
      "epoch: 3550, loss = 0.393153, w = 0.420906, (0.67)\n",
      "ckpt 3550 saved with loss 0.393153\n",
      "epoch: 3560, loss = 0.393483, w = 0.421213, (0.69)\n",
      "epoch: 3570, loss = 0.392176, w = 0.421356, (0.69)\n",
      "epoch: 3580, loss = 0.394119, w = 0.422738, (0.67)\n",
      "epoch: 3590, loss = 0.392230, w = 0.420782, (0.70)\n",
      "epoch: 3600, loss = 0.392923, w = 0.421526, (0.66)\n",
      "ckpt 3600 saved with loss 0.392923\n",
      "epoch: 3610, loss = 0.393650, w = 0.421669, (0.69)\n",
      "epoch: 3620, loss = 0.392792, w = 0.420511, (0.67)\n",
      "epoch: 3630, loss = 0.393072, w = 0.421582, (0.67)\n",
      "epoch: 3640, loss = 0.391601, w = 0.419199, (0.67)\n",
      "epoch: 3650, loss = 0.391972, w = 0.421402, (0.67)\n",
      "ckpt 3650 saved with loss 0.391972\n",
      "epoch: 3660, loss = 0.391985, w = 0.420854, (0.70)\n",
      "epoch: 3670, loss = 0.392505, w = 0.420749, (0.67)\n",
      "epoch: 3680, loss = 0.392303, w = 0.420006, (0.69)\n",
      "epoch: 3690, loss = 0.391479, w = 0.419729, (0.67)\n",
      "epoch: 3700, loss = 0.391235, w = 0.419377, (0.67)\n",
      "ckpt 3700 saved with loss 0.391235\n",
      "epoch: 3710, loss = 0.390811, w = 0.419581, (0.67)\n",
      "epoch: 3720, loss = 0.390801, w = 0.419384, (0.67)\n",
      "epoch: 3730, loss = 0.391111, w = 0.418424, (0.67)\n",
      "epoch: 3740, loss = 0.389907, w = 0.417946, (0.67)\n",
      "epoch: 3750, loss = 0.388708, w = 0.417387, (0.68)\n",
      "ckpt 3750 saved with loss 0.388708\n",
      "epoch: 3760, loss = 0.390258, w = 0.418123, (0.70)\n",
      "epoch: 3770, loss = 0.389088, w = 0.417527, (0.71)\n",
      "epoch: 3780, loss = 0.388943, w = 0.417477, (0.68)\n",
      "epoch: 3790, loss = 0.388946, w = 0.416973, (0.68)\n",
      "epoch: 3800, loss = 0.388881, w = 0.417825, (0.68)\n",
      "epoch: 3810, loss = 0.388908, w = 0.416766, (0.67)\n",
      "epoch: 3820, loss = 0.389311, w = 0.417202, (0.68)\n",
      "epoch: 3830, loss = 0.388961, w = 0.416436, (0.68)\n",
      "epoch: 3840, loss = 0.387502, w = 0.416404, (0.68)\n",
      "epoch: 3850, loss = 0.388787, w = 0.416265, (0.67)\n",
      "epoch: 3860, loss = 0.387650, w = 0.416064, (0.66)\n",
      "epoch: 3870, loss = 0.387697, w = 0.415471, (0.66)\n",
      "epoch: 3880, loss = 0.385786, w = 0.414690, (0.67)\n",
      "epoch: 3890, loss = 0.387437, w = 0.416110, (0.67)\n",
      "epoch: 3900, loss = 0.386366, w = 0.415078, (0.67)\n",
      "ckpt 3900 saved with loss 0.386366\n",
      "epoch: 3910, loss = 0.386099, w = 0.414497, (0.70)\n",
      "epoch: 3920, loss = 0.386569, w = 0.414957, (0.67)\n",
      "epoch: 3930, loss = 0.386420, w = 0.414752, (0.67)\n",
      "epoch: 3940, loss = 0.386179, w = 0.414534, (0.68)\n",
      "epoch: 3950, loss = 0.385811, w = 0.413072, (0.68)\n",
      "ckpt 3950 saved with loss 0.385811\n",
      "epoch: 3960, loss = 0.384223, w = 0.412717, (0.67)\n",
      "epoch: 3970, loss = 0.384967, w = 0.412842, (0.68)\n",
      "epoch: 3980, loss = 0.386303, w = 0.414714, (0.68)\n",
      "epoch: 3990, loss = 0.384656, w = 0.413725, (0.69)\n",
      "epoch: 4000, loss = 0.383941, w = 0.412904, (0.71)\n",
      "ckpt 4000 saved with loss 0.383941\n",
      "epoch: 4010, loss = 0.383799, w = 0.412101, (0.68)\n",
      "epoch: 4020, loss = 0.384193, w = 0.413032, (0.69)\n",
      "epoch: 4030, loss = 0.383350, w = 0.412409, (0.70)\n",
      "epoch: 4040, loss = 0.383132, w = 0.412176, (0.69)\n",
      "epoch: 4050, loss = 0.383507, w = 0.411265, (0.67)\n",
      "ckpt 4050 saved with loss 0.383507\n",
      "epoch: 4060, loss = 0.385627, w = 0.413089, (0.67)\n",
      "epoch: 4070, loss = 0.382609, w = 0.410624, (0.67)\n",
      "epoch: 4080, loss = 0.384306, w = 0.412890, (0.71)\n",
      "epoch: 4090, loss = 0.382476, w = 0.411209, (0.70)\n",
      "2026-02-24 18:03:29.594825: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "epoch: 4100, loss = 0.383584, w = 0.411374, (0.67)\n",
      "epoch: 4110, loss = 0.384068, w = 0.411717, (0.70)\n",
      "epoch: 4120, loss = 0.383239, w = 0.412172, (0.71)\n",
      "epoch: 4130, loss = 0.382267, w = 0.410133, (0.67)\n",
      "epoch: 4140, loss = 0.381742, w = 0.410369, (0.67)\n",
      "epoch: 4150, loss = 0.381847, w = 0.410847, (0.70)\n",
      "ckpt 4150 saved with loss 0.381847\n",
      "epoch: 4160, loss = 0.380818, w = 0.408703, (0.68)\n",
      "epoch: 4170, loss = 0.380481, w = 0.409006, (0.68)\n",
      "epoch: 4180, loss = 0.382262, w = 0.410998, (0.68)\n",
      "epoch: 4190, loss = 0.380395, w = 0.408567, (0.71)\n",
      "epoch: 4200, loss = 0.382316, w = 0.410098, (0.69)\n",
      "epoch: 4210, loss = 0.380461, w = 0.409535, (0.69)\n",
      "epoch: 4220, loss = 0.379341, w = 0.408452, (0.66)\n",
      "epoch: 4230, loss = 0.379283, w = 0.408371, (0.69)\n",
      "epoch: 4240, loss = 0.379868, w = 0.408532, (0.67)\n",
      "epoch: 4250, loss = 0.379639, w = 0.408552, (0.67)\n",
      "ckpt 4250 saved with loss 0.379639\n",
      "epoch: 4260, loss = 0.381162, w = 0.410367, (0.68)\n",
      "epoch: 4270, loss = 0.381198, w = 0.410100, (0.69)\n",
      "epoch: 4280, loss = 0.378548, w = 0.406052, (0.67)\n",
      "epoch: 4290, loss = 0.377860, w = 0.406052, (0.67)\n",
      "epoch: 4300, loss = 0.378456, w = 0.406751, (0.70)\n",
      "ckpt 4300 saved with loss 0.378456\n",
      "epoch: 4310, loss = 0.379069, w = 0.407097, (0.67)\n",
      "epoch: 4320, loss = 0.378341, w = 0.406610, (0.67)\n",
      "epoch: 4330, loss = 0.376045, w = 0.405765, (0.70)\n",
      "epoch: 4340, loss = 0.376227, w = 0.405140, (0.69)\n",
      "epoch: 4350, loss = 0.376093, w = 0.404325, (0.67)\n",
      "ckpt 4350 saved with loss 0.376093\n",
      "epoch: 4360, loss = 0.377378, w = 0.406018, (0.67)\n",
      "epoch: 4370, loss = 0.376451, w = 0.405758, (0.68)\n",
      "epoch: 4380, loss = 0.375559, w = 0.404556, (0.67)\n",
      "epoch: 4390, loss = 0.376277, w = 0.406022, (0.67)\n",
      "epoch: 4400, loss = 0.375528, w = 0.406006, (0.67)\n",
      "ckpt 4400 saved with loss 0.375528\n",
      "epoch: 4410, loss = 0.376498, w = 0.405436, (0.71)\n",
      "epoch: 4420, loss = 0.374840, w = 0.404183, (0.67)\n",
      "epoch: 4430, loss = 0.375851, w = 0.404562, (0.68)\n",
      "epoch: 4440, loss = 0.373544, w = 0.403904, (0.68)\n",
      "epoch: 4450, loss = 0.374790, w = 0.404593, (0.68)\n",
      "ckpt 4450 saved with loss 0.374790\n",
      "epoch: 4460, loss = 0.374395, w = 0.403755, (0.67)\n",
      "epoch: 4470, loss = 0.372038, w = 0.401598, (0.69)\n",
      "epoch: 4480, loss = 0.371443, w = 0.402661, (0.68)\n",
      "epoch: 4490, loss = 0.373830, w = 0.402923, (0.69)\n",
      "epoch: 4500, loss = 0.372580, w = 0.403195, (0.70)\n",
      "ckpt 4500 saved with loss 0.372580\n",
      "epoch: 4510, loss = 0.372957, w = 0.403372, (0.68)\n",
      "epoch: 4520, loss = 0.373223, w = 0.403497, (0.71)\n",
      "epoch: 4530, loss = 0.373929, w = 0.403068, (0.68)\n",
      "epoch: 4540, loss = 0.370850, w = 0.401153, (0.67)\n",
      "epoch: 4550, loss = 0.372511, w = 0.400785, (0.67)\n",
      "ckpt 4550 saved with loss 0.372511\n",
      "epoch: 4560, loss = 0.372164, w = 0.402264, (0.68)\n",
      "epoch: 4570, loss = 0.373085, w = 0.402027, (0.68)\n",
      "epoch: 4580, loss = 0.370655, w = 0.401065, (0.67)\n",
      "epoch: 4590, loss = 0.370462, w = 0.399406, (0.70)\n",
      "epoch: 4600, loss = 0.371069, w = 0.401972, (0.68)\n",
      "ckpt 4600 saved with loss 0.371069\n",
      "epoch: 4610, loss = 0.370317, w = 0.400518, (0.70)\n",
      "epoch: 4620, loss = 0.369924, w = 0.399868, (0.66)\n",
      "epoch: 4630, loss = 0.369819, w = 0.399487, (0.68)\n",
      "epoch: 4640, loss = 0.370913, w = 0.401128, (0.69)\n",
      "epoch: 4650, loss = 0.370464, w = 0.401282, (0.69)\n",
      "ckpt 4650 saved with loss 0.370464\n",
      "epoch: 4660, loss = 0.369865, w = 0.400250, (0.70)\n",
      "epoch: 4670, loss = 0.369382, w = 0.399724, (0.67)\n",
      "epoch: 4680, loss = 0.369019, w = 0.399135, (0.67)\n",
      "epoch: 4690, loss = 0.368718, w = 0.398695, (0.68)\n",
      "epoch: 4700, loss = 0.370121, w = 0.399985, (0.67)\n",
      "ckpt 4700 saved with loss 0.370121\n",
      "epoch: 4710, loss = 0.368359, w = 0.398873, (0.68)\n",
      "epoch: 4720, loss = 0.367604, w = 0.397806, (0.68)\n",
      "epoch: 4730, loss = 0.369160, w = 0.400621, (0.71)\n",
      "epoch: 4740, loss = 0.368749, w = 0.398460, (0.70)\n",
      "epoch: 4750, loss = 0.367942, w = 0.398141, (0.67)\n",
      "ckpt 4750 saved with loss 0.367942\n",
      "epoch: 4760, loss = 0.367619, w = 0.396836, (0.69)\n",
      "epoch: 4770, loss = 0.367131, w = 0.397576, (0.67)\n",
      "epoch: 4780, loss = 0.367294, w = 0.397021, (0.70)\n",
      "epoch: 4790, loss = 0.365299, w = 0.396761, (0.68)\n",
      "epoch: 4800, loss = 0.366602, w = 0.396562, (0.69)\n",
      "ckpt 4800 saved with loss 0.366602\n",
      "epoch: 4810, loss = 0.367866, w = 0.396658, (0.67)\n",
      "epoch: 4820, loss = 0.368113, w = 0.397218, (0.68)\n",
      "epoch: 4830, loss = 0.365156, w = 0.395916, (0.69)\n",
      "epoch: 4840, loss = 0.365237, w = 0.396188, (0.70)\n",
      "epoch: 4850, loss = 0.366349, w = 0.396663, (0.69)\n",
      "ckpt 4850 saved with loss 0.366349\n",
      "epoch: 4860, loss = 0.365287, w = 0.394961, (0.67)\n",
      "epoch: 4870, loss = 0.367365, w = 0.396895, (0.67)\n",
      "epoch: 4880, loss = 0.366559, w = 0.396615, (0.67)\n",
      "epoch: 4890, loss = 0.365932, w = 0.395999, (0.69)\n",
      "epoch: 4900, loss = 0.365314, w = 0.396791, (0.68)\n",
      "ckpt 4900 saved with loss 0.365314\n",
      "epoch: 4910, loss = 0.362315, w = 0.393968, (0.68)\n",
      "epoch: 4920, loss = 0.364968, w = 0.396097, (0.68)\n",
      "epoch: 4930, loss = 0.362237, w = 0.393730, (0.68)\n",
      "epoch: 4940, loss = 0.363901, w = 0.393772, (0.70)\n",
      "epoch: 4950, loss = 0.363688, w = 0.393326, (0.67)\n",
      "ckpt 4950 saved with loss 0.363688\n",
      "epoch: 4960, loss = 0.363183, w = 0.393305, (0.68)\n",
      "epoch: 4970, loss = 0.365715, w = 0.395368, (0.67)\n",
      "epoch: 4980, loss = 0.362698, w = 0.394358, (0.69)\n",
      "epoch: 4990, loss = 0.363053, w = 0.393128, (0.69)\n",
      "epoch: 5000, loss = 0.361943, w = 0.392798, (0.69)\n",
      "ckpt 5000 saved with loss 0.361943\n",
      "epoch: 5010, loss = 0.362709, w = 0.392428, (0.68)\n",
      "epoch: 5020, loss = 0.362257, w = 0.392855, (0.67)\n",
      "epoch: 5030, loss = 0.362113, w = 0.392729, (0.69)\n",
      "epoch: 5040, loss = 0.361521, w = 0.391274, (0.67)\n",
      "epoch: 5050, loss = 0.361472, w = 0.391615, (0.67)\n",
      "ckpt 5050 saved with loss 0.361472\n",
      "epoch: 5060, loss = 0.361073, w = 0.391480, (0.67)\n",
      "epoch: 5070, loss = 0.362867, w = 0.393623, (0.68)\n",
      "epoch: 5080, loss = 0.361335, w = 0.391815, (0.67)\n",
      "epoch: 5090, loss = 0.362168, w = 0.392297, (0.67)\n",
      "epoch: 5100, loss = 0.361913, w = 0.391675, (0.69)\n",
      "epoch: 5110, loss = 0.360203, w = 0.391086, (0.68)\n",
      "epoch: 5120, loss = 0.358554, w = 0.390514, (0.68)\n",
      "epoch: 5130, loss = 0.358386, w = 0.388619, (0.68)\n",
      "epoch: 5140, loss = 0.360478, w = 0.389960, (0.68)\n",
      "epoch: 5150, loss = 0.360172, w = 0.390493, (0.69)\n",
      "ckpt 5150 saved with loss 0.360172\n",
      "epoch: 5160, loss = 0.359223, w = 0.389512, (0.74)\n",
      "epoch: 5170, loss = 0.362106, w = 0.391640, (0.69)\n",
      "epoch: 5180, loss = 0.357666, w = 0.387723, (0.68)\n",
      "epoch: 5190, loss = 0.358918, w = 0.389294, (0.68)\n",
      "epoch: 5200, loss = 0.357646, w = 0.388726, (0.68)\n",
      "ckpt 5200 saved with loss 0.357646\n",
      "epoch: 5210, loss = 0.358050, w = 0.387713, (0.67)\n",
      "epoch: 5220, loss = 0.359127, w = 0.389955, (0.67)\n",
      "epoch: 5230, loss = 0.355593, w = 0.387563, (0.67)\n",
      "epoch: 5240, loss = 0.355902, w = 0.387972, (0.67)\n",
      "epoch: 5250, loss = 0.357120, w = 0.387234, (0.67)\n",
      "ckpt 5250 saved with loss 0.357120\n",
      "epoch: 5260, loss = 0.355866, w = 0.386044, (0.67)\n",
      "epoch: 5270, loss = 0.356619, w = 0.386244, (0.68)\n",
      "epoch: 5280, loss = 0.356848, w = 0.387765, (0.69)\n",
      "epoch: 5290, loss = 0.357720, w = 0.387284, (0.66)\n",
      "epoch: 5300, loss = 0.355403, w = 0.386367, (0.67)\n",
      "ckpt 5300 saved with loss 0.355403\n",
      "epoch: 5310, loss = 0.356730, w = 0.386393, (0.67)\n",
      "epoch: 5320, loss = 0.354107, w = 0.383438, (0.68)\n",
      "epoch: 5330, loss = 0.356957, w = 0.386436, (0.66)\n",
      "epoch: 5340, loss = 0.356168, w = 0.386725, (0.67)\n",
      "epoch: 5350, loss = 0.353736, w = 0.383940, (0.66)\n",
      "ckpt 5350 saved with loss 0.353736\n",
      "epoch: 5360, loss = 0.353838, w = 0.383315, (0.67)\n",
      "epoch: 5370, loss = 0.355944, w = 0.385011, (0.67)\n",
      "epoch: 5380, loss = 0.356683, w = 0.385629, (0.67)\n",
      "epoch: 5390, loss = 0.352835, w = 0.382840, (0.66)\n",
      "epoch: 5400, loss = 0.354596, w = 0.384756, (0.67)\n",
      "epoch: 5410, loss = 0.352965, w = 0.382383, (0.68)\n",
      "epoch: 5420, loss = 0.356131, w = 0.385383, (0.68)\n",
      "epoch: 5430, loss = 0.353674, w = 0.383060, (0.68)\n",
      "epoch: 5440, loss = 0.354315, w = 0.383692, (0.67)\n",
      "epoch: 5450, loss = 0.354238, w = 0.383493, (0.67)\n",
      "epoch: 5460, loss = 0.352672, w = 0.381749, (0.68)\n",
      "epoch: 5470, loss = 0.354756, w = 0.383863, (0.66)\n",
      "epoch: 5480, loss = 0.352586, w = 0.381868, (0.67)\n",
      "epoch: 5490, loss = 0.352674, w = 0.382125, (0.69)\n",
      "epoch: 5500, loss = 0.354591, w = 0.382936, (0.66)\n",
      "epoch: 5510, loss = 0.353590, w = 0.383013, (0.66)\n",
      "epoch: 5520, loss = 0.354502, w = 0.382742, (0.68)\n",
      "epoch: 5530, loss = 0.351082, w = 0.382574, (0.66)\n",
      "epoch: 5540, loss = 0.350932, w = 0.380930, (0.66)\n",
      "epoch: 5550, loss = 0.350945, w = 0.380494, (0.66)\n",
      "ckpt 5550 saved with loss 0.350945\n",
      "epoch: 5560, loss = 0.351074, w = 0.380705, (0.69)\n",
      "epoch: 5570, loss = 0.349912, w = 0.379510, (0.66)\n",
      "epoch: 5580, loss = 0.351036, w = 0.380425, (0.66)\n",
      "epoch: 5590, loss = 0.351445, w = 0.380932, (0.68)\n",
      "epoch: 5600, loss = 0.347856, w = 0.377831, (0.67)\n",
      "ckpt 5600 saved with loss 0.347856\n",
      "epoch: 5610, loss = 0.350128, w = 0.379479, (0.67)\n",
      "epoch: 5620, loss = 0.350892, w = 0.380039, (0.66)\n",
      "epoch: 5630, loss = 0.350730, w = 0.380930, (0.68)\n",
      "epoch: 5640, loss = 0.349771, w = 0.380309, (0.67)\n",
      "epoch: 5650, loss = 0.351200, w = 0.379599, (0.66)\n",
      "epoch: 5660, loss = 0.348693, w = 0.378010, (0.66)\n",
      "epoch: 5670, loss = 0.349045, w = 0.378290, (0.67)\n",
      "epoch: 5680, loss = 0.349180, w = 0.378657, (0.67)\n",
      "epoch: 5690, loss = 0.349828, w = 0.379623, (0.66)\n",
      "epoch: 5700, loss = 0.350000, w = 0.377833, (0.67)\n",
      "epoch: 5710, loss = 0.348909, w = 0.377942, (0.66)\n",
      "epoch: 5720, loss = 0.350346, w = 0.380033, (0.66)\n",
      "epoch: 5730, loss = 0.348591, w = 0.378285, (0.68)\n",
      "epoch: 5740, loss = 0.349070, w = 0.378704, (0.68)\n",
      "epoch: 5750, loss = 0.348125, w = 0.377615, (0.67)\n",
      "epoch: 5760, loss = 0.346745, w = 0.376895, (0.66)\n",
      "epoch: 5770, loss = 0.346662, w = 0.376655, (0.68)\n",
      "epoch: 5780, loss = 0.348111, w = 0.376838, (0.69)\n",
      "epoch: 5790, loss = 0.347190, w = 0.376330, (0.67)\n",
      "epoch: 5800, loss = 0.347644, w = 0.377748, (0.66)\n",
      "ckpt 5800 saved with loss 0.347644\n",
      "epoch: 5810, loss = 0.343261, w = 0.374010, (0.66)\n",
      "epoch: 5820, loss = 0.345653, w = 0.375768, (0.66)\n",
      "epoch: 5830, loss = 0.345808, w = 0.375052, (0.68)\n",
      "epoch: 5840, loss = 0.346715, w = 0.376383, (0.67)\n",
      "epoch: 5850, loss = 0.347014, w = 0.376152, (0.66)\n",
      "ckpt 5850 saved with loss 0.347014\n",
      "epoch: 5860, loss = 0.345217, w = 0.376090, (0.72)\n",
      "epoch: 5870, loss = 0.347308, w = 0.376419, (0.67)\n",
      "epoch: 5880, loss = 0.348558, w = 0.377513, (0.67)\n",
      "epoch: 5890, loss = 0.346489, w = 0.376177, (0.66)\n",
      "epoch: 5900, loss = 0.346627, w = 0.376595, (0.68)\n",
      "ckpt 5900 saved with loss 0.346627\n",
      "epoch: 5910, loss = 0.345906, w = 0.375042, (0.66)\n",
      "epoch: 5920, loss = 0.345534, w = 0.373790, (0.67)\n",
      "epoch: 5930, loss = 0.345702, w = 0.374151, (0.69)\n",
      "epoch: 5940, loss = 0.344353, w = 0.373667, (0.68)\n",
      "epoch: 5950, loss = 0.346270, w = 0.374622, (0.68)\n",
      "ckpt 5950 saved with loss 0.346270\n",
      "epoch: 5960, loss = 0.345821, w = 0.374641, (0.67)\n",
      "epoch: 5970, loss = 0.346663, w = 0.375772, (0.67)\n",
      "epoch: 5980, loss = 0.347203, w = 0.375182, (0.67)\n",
      "epoch: 5990, loss = 0.343576, w = 0.372479, (0.67)\n",
      "epoch: 6000, loss = 0.344526, w = 0.372881, (0.66)\n",
      "ckpt 6000 saved with loss 0.344526\n",
      "epoch: 6010, loss = 0.345090, w = 0.374858, (0.67)\n",
      "epoch: 6020, loss = 0.343407, w = 0.372936, (0.67)\n",
      "epoch: 6030, loss = 0.344115, w = 0.373318, (0.66)\n",
      "epoch: 6040, loss = 0.343039, w = 0.372341, (0.67)\n",
      "epoch: 6050, loss = 0.342459, w = 0.372133, (0.67)\n",
      "ckpt 6050 saved with loss 0.342459\n",
      "epoch: 6060, loss = 0.342571, w = 0.372110, (0.68)\n",
      "epoch: 6070, loss = 0.342678, w = 0.371907, (0.66)\n",
      "epoch: 6080, loss = 0.342425, w = 0.371180, (0.66)\n",
      "epoch: 6090, loss = 0.342727, w = 0.371307, (0.67)\n",
      "epoch: 6100, loss = 0.341955, w = 0.371100, (0.67)\n",
      "ckpt 6100 saved with loss 0.341955\n",
      "epoch: 6110, loss = 0.343917, w = 0.373120, (0.68)\n",
      "epoch: 6120, loss = 0.343101, w = 0.372739, (0.69)\n",
      "epoch: 6130, loss = 0.340840, w = 0.370265, (0.67)\n",
      "epoch: 6140, loss = 0.341485, w = 0.371308, (0.68)\n",
      "epoch: 6150, loss = 0.343075, w = 0.371681, (0.70)\n",
      "epoch: 6160, loss = 0.341792, w = 0.371654, (0.68)\n",
      "epoch: 6170, loss = 0.340735, w = 0.369995, (0.66)\n",
      "epoch: 6180, loss = 0.340755, w = 0.369856, (0.66)\n",
      "epoch: 6190, loss = 0.340270, w = 0.369186, (0.66)\n",
      "epoch: 6200, loss = 0.340535, w = 0.369112, (0.67)\n",
      "ckpt 6200 saved with loss 0.340535\n",
      "epoch: 6210, loss = 0.342284, w = 0.371483, (0.67)\n",
      "epoch: 6220, loss = 0.341887, w = 0.369340, (0.68)\n",
      "epoch: 6230, loss = 0.341104, w = 0.369511, (0.66)\n",
      "epoch: 6240, loss = 0.339789, w = 0.368254, (0.67)\n",
      "epoch: 6250, loss = 0.338064, w = 0.368892, (0.66)\n",
      "ckpt 6250 saved with loss 0.338064\n",
      "epoch: 6260, loss = 0.340024, w = 0.369355, (0.67)\n",
      "epoch: 6270, loss = 0.334356, w = 0.363651, (0.66)\n",
      "epoch: 6280, loss = 0.339825, w = 0.367017, (0.67)\n",
      "epoch: 6290, loss = 0.336732, w = 0.366190, (0.67)\n",
      "epoch: 6300, loss = 0.336407, w = 0.365454, (0.66)\n",
      "ckpt 6300 saved with loss 0.336407\n",
      "epoch: 6310, loss = 0.336710, w = 0.367283, (0.66)\n",
      "epoch: 6320, loss = 0.337726, w = 0.366040, (0.67)\n",
      "epoch: 6330, loss = 0.339175, w = 0.367671, (0.68)\n",
      "epoch: 6340, loss = 0.337141, w = 0.365624, (0.66)\n",
      "epoch: 6350, loss = 0.334217, w = 0.364525, (0.70)\n",
      "ckpt 6350 saved with loss 0.334217\n",
      "epoch: 6360, loss = 0.337231, w = 0.367087, (0.66)\n",
      "epoch: 6370, loss = 0.337385, w = 0.366673, (0.67)\n",
      "epoch: 6380, loss = 0.338605, w = 0.367756, (0.68)\n",
      "epoch: 6390, loss = 0.339069, w = 0.367919, (0.66)\n",
      "epoch: 6400, loss = 0.339119, w = 0.367626, (0.67)\n",
      "epoch: 6410, loss = 0.336692, w = 0.365208, (0.67)\n",
      "epoch: 6420, loss = 0.337460, w = 0.365593, (0.67)\n",
      "epoch: 6430, loss = 0.335476, w = 0.364993, (0.66)\n",
      "epoch: 6440, loss = 0.338186, w = 0.367553, (0.68)\n",
      "epoch: 6450, loss = 0.337361, w = 0.365478, (0.67)\n",
      "epoch: 6460, loss = 0.335767, w = 0.365759, (0.68)\n",
      "epoch: 6470, loss = 0.336218, w = 0.364525, (0.66)\n",
      "epoch: 6480, loss = 0.336419, w = 0.365604, (0.66)\n",
      "epoch: 6490, loss = 0.336390, w = 0.364266, (0.66)\n",
      "epoch: 6500, loss = 0.335355, w = 0.364209, (0.66)\n",
      "epoch: 6510, loss = 0.335871, w = 0.363936, (0.68)\n",
      "epoch: 6520, loss = 0.335816, w = 0.364886, (0.66)\n",
      "epoch: 6530, loss = 0.335250, w = 0.364278, (0.68)\n",
      "epoch: 6540, loss = 0.337246, w = 0.364729, (0.66)\n",
      "epoch: 6550, loss = 0.333880, w = 0.363656, (0.66)\n",
      "ckpt 6550 saved with loss 0.333880\n",
      "epoch: 6560, loss = 0.335777, w = 0.363426, (0.68)\n",
      "epoch: 6570, loss = 0.332826, w = 0.363119, (0.67)\n",
      "epoch: 6580, loss = 0.333486, w = 0.363303, (0.68)\n",
      "epoch: 6590, loss = 0.335001, w = 0.363411, (0.67)\n",
      "epoch: 6600, loss = 0.335208, w = 0.364171, (0.66)\n",
      "epoch: 6610, loss = 0.333566, w = 0.363056, (0.66)\n",
      "epoch: 6620, loss = 0.333804, w = 0.363218, (0.67)\n",
      "epoch: 6630, loss = 0.333922, w = 0.362006, (0.66)\n",
      "epoch: 6640, loss = 0.334004, w = 0.362423, (0.67)\n",
      "epoch: 6650, loss = 0.334525, w = 0.363730, (0.68)\n",
      "epoch: 6660, loss = 0.334277, w = 0.363054, (0.66)\n",
      "epoch: 6670, loss = 0.332682, w = 0.362726, (0.67)\n",
      "epoch: 6680, loss = 0.332747, w = 0.362388, (0.67)\n",
      "epoch: 6690, loss = 0.332362, w = 0.361381, (0.67)\n",
      "epoch: 6700, loss = 0.332674, w = 0.360779, (0.67)\n",
      "ckpt 6700 saved with loss 0.332674\n",
      "epoch: 6710, loss = 0.329750, w = 0.360652, (0.67)\n",
      "epoch: 6720, loss = 0.332946, w = 0.360681, (0.66)\n",
      "epoch: 6730, loss = 0.333398, w = 0.361752, (0.66)\n",
      "epoch: 6740, loss = 0.331246, w = 0.359239, (0.67)\n",
      "epoch: 6750, loss = 0.329928, w = 0.357952, (0.67)\n",
      "ckpt 6750 saved with loss 0.329928\n",
      "epoch: 6760, loss = 0.331631, w = 0.360557, (0.66)\n",
      "epoch: 6770, loss = 0.332783, w = 0.361421, (0.67)\n",
      "epoch: 6780, loss = 0.330633, w = 0.359766, (0.67)\n",
      "epoch: 6790, loss = 0.332410, w = 0.359808, (0.67)\n",
      "epoch: 6800, loss = 0.331174, w = 0.360942, (0.69)\n",
      "epoch: 6810, loss = 0.329175, w = 0.358572, (0.66)\n",
      "epoch: 6820, loss = 0.331644, w = 0.359646, (0.67)\n",
      "epoch: 6830, loss = 0.328761, w = 0.358080, (0.66)\n",
      "epoch: 6840, loss = 0.330660, w = 0.359195, (0.67)\n",
      "epoch: 6850, loss = 0.330551, w = 0.358683, (0.68)\n",
      "epoch: 6860, loss = 0.329169, w = 0.358416, (0.66)\n",
      "epoch: 6870, loss = 0.331379, w = 0.359113, (0.67)\n",
      "epoch: 6880, loss = 0.329099, w = 0.358475, (0.66)\n",
      "epoch: 6890, loss = 0.329178, w = 0.358461, (0.67)\n",
      "epoch: 6900, loss = 0.330343, w = 0.359081, (0.67)\n",
      "epoch: 6910, loss = 0.326713, w = 0.356437, (0.67)\n",
      "epoch: 6920, loss = 0.327650, w = 0.357199, (0.67)\n",
      "epoch: 6930, loss = 0.330336, w = 0.358863, (0.67)\n",
      "epoch: 6940, loss = 0.325679, w = 0.356346, (0.67)\n",
      "epoch: 6950, loss = 0.328508, w = 0.357121, (0.66)\n",
      "ckpt 6950 saved with loss 0.328508\n",
      "epoch: 6960, loss = 0.329848, w = 0.357860, (0.69)\n",
      "epoch: 6970, loss = 0.329400, w = 0.357843, (0.67)\n",
      "epoch: 6980, loss = 0.328961, w = 0.356642, (0.67)\n",
      "epoch: 6990, loss = 0.327765, w = 0.356508, (0.66)\n",
      "epoch: 7000, loss = 0.329673, w = 0.357668, (0.72)\n",
      "epoch: 7010, loss = 0.327302, w = 0.355175, (0.71)\n",
      "epoch: 7020, loss = 0.325988, w = 0.355287, (0.66)\n",
      "epoch: 7030, loss = 0.326579, w = 0.355373, (0.70)\n",
      "epoch: 7040, loss = 0.328300, w = 0.356190, (0.67)\n",
      "epoch: 7050, loss = 0.329065, w = 0.356861, (0.67)\n",
      "epoch: 7060, loss = 0.327412, w = 0.356196, (0.67)\n",
      "epoch: 7070, loss = 0.327707, w = 0.355758, (0.69)\n",
      "epoch: 7080, loss = 0.328834, w = 0.357515, (0.67)\n",
      "epoch: 7090, loss = 0.326712, w = 0.355602, (0.67)\n",
      "epoch: 7100, loss = 0.326025, w = 0.354663, (0.66)\n",
      "ckpt 7100 saved with loss 0.326025\n",
      "epoch: 7110, loss = 0.327605, w = 0.355927, (0.67)\n",
      "epoch: 7120, loss = 0.327677, w = 0.355844, (0.68)\n",
      "epoch: 7130, loss = 0.325668, w = 0.354337, (0.67)\n",
      "epoch: 7140, loss = 0.324494, w = 0.352988, (0.68)\n",
      "epoch: 7150, loss = 0.323542, w = 0.353049, (0.67)\n",
      "ckpt 7150 saved with loss 0.323542\n",
      "epoch: 7160, loss = 0.324352, w = 0.353976, (0.70)\n",
      "epoch: 7170, loss = 0.325532, w = 0.354763, (0.67)\n",
      "epoch: 7180, loss = 0.324448, w = 0.353087, (0.68)\n",
      "epoch: 7190, loss = 0.327050, w = 0.355465, (0.66)\n",
      "epoch: 7200, loss = 0.325988, w = 0.353415, (0.67)\n",
      "epoch: 7210, loss = 0.324442, w = 0.353388, (0.69)\n",
      "epoch: 7220, loss = 0.322438, w = 0.352151, (0.67)\n",
      "epoch: 7230, loss = 0.324048, w = 0.352854, (0.69)\n",
      "epoch: 7240, loss = 0.324598, w = 0.352635, (0.67)\n",
      "epoch: 7250, loss = 0.324864, w = 0.353776, (0.69)\n",
      "epoch: 7260, loss = 0.323054, w = 0.352921, (0.68)\n",
      "epoch: 7270, loss = 0.324678, w = 0.352870, (0.67)\n",
      "epoch: 7280, loss = 0.326038, w = 0.354067, (0.70)\n",
      "epoch: 7290, loss = 0.325601, w = 0.353335, (0.68)\n",
      "epoch: 7300, loss = 0.326038, w = 0.354216, (0.67)\n",
      "epoch: 7310, loss = 0.320890, w = 0.350000, (0.67)\n",
      "epoch: 7320, loss = 0.324649, w = 0.352367, (0.71)\n",
      "epoch: 7330, loss = 0.323901, w = 0.352396, (0.66)\n",
      "epoch: 7340, loss = 0.322866, w = 0.350774, (0.67)\n",
      "epoch: 7350, loss = 0.322522, w = 0.350452, (0.67)\n",
      "ckpt 7350 saved with loss 0.322522\n",
      "epoch: 7360, loss = 0.321905, w = 0.349887, (0.66)\n",
      "epoch: 7370, loss = 0.323629, w = 0.351936, (0.67)\n",
      "epoch: 7380, loss = 0.324676, w = 0.352360, (0.67)\n",
      "epoch: 7390, loss = 0.322464, w = 0.351164, (0.71)\n",
      "epoch: 7400, loss = 0.323474, w = 0.351237, (0.67)\n",
      "epoch: 7410, loss = 0.320776, w = 0.348466, (0.67)\n",
      "epoch: 7420, loss = 0.321784, w = 0.349955, (0.68)\n",
      "epoch: 7430, loss = 0.322438, w = 0.350467, (0.68)\n",
      "epoch: 7440, loss = 0.319921, w = 0.348675, (0.68)\n",
      "epoch: 7450, loss = 0.321057, w = 0.349682, (0.68)\n",
      "ckpt 7450 saved with loss 0.321057\n",
      "epoch: 7460, loss = 0.321220, w = 0.348722, (0.72)\n",
      "epoch: 7470, loss = 0.321073, w = 0.348691, (0.69)\n",
      "epoch: 7480, loss = 0.322594, w = 0.350756, (0.67)\n",
      "epoch: 7490, loss = 0.320045, w = 0.347811, (0.67)\n",
      "epoch: 7500, loss = 0.321542, w = 0.348405, (0.70)\n",
      "epoch: 7510, loss = 0.321217, w = 0.348418, (0.67)\n",
      "epoch: 7520, loss = 0.319014, w = 0.346743, (0.67)\n",
      "epoch: 7530, loss = 0.316785, w = 0.346625, (0.67)\n",
      "epoch: 7540, loss = 0.320795, w = 0.349121, (0.67)\n",
      "epoch: 7550, loss = 0.318140, w = 0.347780, (0.72)\n",
      "ckpt 7550 saved with loss 0.318140\n",
      "epoch: 7560, loss = 0.318879, w = 0.347764, (0.67)\n",
      "epoch: 7570, loss = 0.319447, w = 0.348304, (0.67)\n",
      "epoch: 7580, loss = 0.317535, w = 0.346895, (0.69)\n",
      "epoch: 7590, loss = 0.321721, w = 0.349166, (0.66)\n",
      "epoch: 7600, loss = 0.317289, w = 0.347106, (0.70)\n",
      "ckpt 7600 saved with loss 0.317289\n",
      "epoch: 7610, loss = 0.318126, w = 0.346410, (0.68)\n",
      "epoch: 7620, loss = 0.318723, w = 0.348068, (0.68)\n",
      "epoch: 7630, loss = 0.319074, w = 0.347668, (0.68)\n",
      "epoch: 7640, loss = 0.318430, w = 0.345966, (0.67)\n",
      "epoch: 7650, loss = 0.319190, w = 0.347587, (0.66)\n",
      "epoch: 7660, loss = 0.316558, w = 0.345235, (0.67)\n",
      "epoch: 7670, loss = 0.318704, w = 0.346695, (0.69)\n",
      "epoch: 7680, loss = 0.316384, w = 0.344548, (0.67)\n",
      "epoch: 7690, loss = 0.318838, w = 0.346680, (0.67)\n",
      "epoch: 7700, loss = 0.316525, w = 0.344722, (0.70)\n",
      "ckpt 7700 saved with loss 0.316525\n",
      "epoch: 7710, loss = 0.316379, w = 0.344358, (0.66)\n",
      "epoch: 7720, loss = 0.316391, w = 0.344729, (0.67)\n",
      "epoch: 7730, loss = 0.315270, w = 0.343318, (0.68)\n",
      "epoch: 7740, loss = 0.315933, w = 0.343951, (0.69)\n",
      "epoch: 7750, loss = 0.316876, w = 0.344700, (0.67)\n",
      "epoch: 7760, loss = 0.316364, w = 0.343854, (0.67)\n",
      "epoch: 7770, loss = 0.315451, w = 0.342422, (0.69)\n",
      "epoch: 7780, loss = 0.314593, w = 0.343356, (0.66)\n",
      "epoch: 7790, loss = 0.316848, w = 0.344317, (0.66)\n",
      "epoch: 7800, loss = 0.317640, w = 0.344536, (0.67)\n",
      "epoch: 7810, loss = 0.315861, w = 0.343371, (0.69)\n",
      "epoch: 7820, loss = 0.313651, w = 0.341877, (0.67)\n",
      "epoch: 7830, loss = 0.314153, w = 0.342783, (0.66)\n",
      "epoch: 7840, loss = 0.315074, w = 0.343896, (0.69)\n",
      "epoch: 7850, loss = 0.314494, w = 0.342534, (0.67)\n",
      "ckpt 7850 saved with loss 0.314494\n",
      "epoch: 7860, loss = 0.313550, w = 0.340747, (0.68)\n",
      "epoch: 7870, loss = 0.314511, w = 0.343080, (0.66)\n",
      "epoch: 7880, loss = 0.315558, w = 0.342978, (0.71)\n",
      "epoch: 7890, loss = 0.313764, w = 0.342020, (0.67)\n",
      "epoch: 7900, loss = 0.314281, w = 0.341938, (0.67)\n",
      "ckpt 7900 saved with loss 0.314281\n",
      "epoch: 7910, loss = 0.314323, w = 0.341344, (0.68)\n",
      "epoch: 7920, loss = 0.314018, w = 0.341743, (0.68)\n",
      "epoch: 7930, loss = 0.313720, w = 0.341761, (0.66)\n",
      "epoch: 7940, loss = 0.313582, w = 0.340144, (0.66)\n",
      "epoch: 7950, loss = 0.313997, w = 0.341720, (0.69)\n",
      "ckpt 7950 saved with loss 0.313997\n",
      "epoch: 7960, loss = 0.313382, w = 0.340544, (0.68)\n",
      "epoch: 7970, loss = 0.313668, w = 0.340392, (0.67)\n",
      "epoch: 7980, loss = 0.312972, w = 0.341208, (0.69)\n",
      "epoch: 7990, loss = 0.312735, w = 0.340980, (0.68)\n",
      "epoch: 8000, loss = 0.313453, w = 0.341338, (0.68)\n",
      "ckpt 8000 saved with loss 0.313453\n",
      "epoch: 8010, loss = 0.312713, w = 0.340353, (0.70)\n",
      "epoch: 8020, loss = 0.312740, w = 0.340057, (0.67)\n",
      "epoch: 8030, loss = 0.314473, w = 0.341004, (0.68)\n",
      "epoch: 8040, loss = 0.313578, w = 0.341117, (0.68)\n",
      "epoch: 8050, loss = 0.313461, w = 0.341206, (0.66)\n",
      "epoch: 8060, loss = 0.313063, w = 0.340156, (0.67)\n",
      "epoch: 8070, loss = 0.312481, w = 0.340076, (0.67)\n",
      "epoch: 8080, loss = 0.314356, w = 0.340715, (0.69)\n",
      "epoch: 8090, loss = 0.311157, w = 0.339282, (0.69)\n",
      "epoch: 8100, loss = 0.312030, w = 0.339802, (0.67)\n",
      "ckpt 8100 saved with loss 0.312030\n",
      "epoch: 8110, loss = 0.309807, w = 0.338929, (0.68)\n",
      "epoch: 8120, loss = 0.311828, w = 0.339934, (0.68)\n",
      "epoch: 8130, loss = 0.310879, w = 0.338625, (0.67)\n",
      "epoch: 8140, loss = 0.309462, w = 0.338584, (0.68)\n",
      "epoch: 8150, loss = 0.310790, w = 0.337625, (0.70)\n",
      "ckpt 8150 saved with loss 0.310790\n",
      "epoch: 8160, loss = 0.313429, w = 0.340511, (0.67)\n",
      "epoch: 8170, loss = 0.311889, w = 0.339365, (0.67)\n",
      "epoch: 8180, loss = 0.309768, w = 0.338713, (0.67)\n",
      "epoch: 8190, loss = 0.311035, w = 0.339620, (0.68)\n",
      "2026-02-24 18:49:40.452540: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "epoch: 8200, loss = 0.310855, w = 0.338339, (0.67)\n",
      "epoch: 8210, loss = 0.312223, w = 0.339147, (0.68)\n",
      "epoch: 8220, loss = 0.310373, w = 0.337537, (0.70)\n",
      "epoch: 8230, loss = 0.312650, w = 0.339590, (0.67)\n",
      "epoch: 8240, loss = 0.310262, w = 0.338252, (0.67)\n",
      "epoch: 8250, loss = 0.311355, w = 0.338900, (0.67)\n",
      "epoch: 8260, loss = 0.309717, w = 0.336527, (0.69)\n",
      "epoch: 8270, loss = 0.310054, w = 0.337894, (0.68)\n",
      "epoch: 8280, loss = 0.309440, w = 0.336810, (0.67)\n",
      "epoch: 8290, loss = 0.310662, w = 0.337459, (0.68)\n",
      "epoch: 8300, loss = 0.308259, w = 0.336585, (0.67)\n",
      "ckpt 8300 saved with loss 0.308259\n",
      "epoch: 8310, loss = 0.308025, w = 0.335411, (0.67)\n",
      "epoch: 8320, loss = 0.309120, w = 0.336586, (0.67)\n",
      "epoch: 8330, loss = 0.309939, w = 0.337710, (0.70)\n",
      "epoch: 8340, loss = 0.308912, w = 0.336345, (0.68)\n",
      "epoch: 8350, loss = 0.308555, w = 0.335920, (0.68)\n",
      "epoch: 8360, loss = 0.309002, w = 0.336113, (0.68)\n",
      "epoch: 8370, loss = 0.307193, w = 0.336362, (0.66)\n",
      "epoch: 8380, loss = 0.309037, w = 0.337177, (0.66)\n",
      "epoch: 8390, loss = 0.309307, w = 0.337208, (0.66)\n",
      "epoch: 8400, loss = 0.307854, w = 0.335256, (0.69)\n",
      "ckpt 8400 saved with loss 0.307854\n",
      "epoch: 8410, loss = 0.307831, w = 0.335221, (0.68)\n",
      "epoch: 8420, loss = 0.307587, w = 0.334561, (0.70)\n",
      "epoch: 8430, loss = 0.308781, w = 0.336397, (0.66)\n",
      "epoch: 8440, loss = 0.308869, w = 0.336018, (0.67)\n",
      "epoch: 8450, loss = 0.306059, w = 0.333990, (0.69)\n",
      "ckpt 8450 saved with loss 0.306059\n",
      "epoch: 8460, loss = 0.310118, w = 0.336774, (0.69)\n",
      "epoch: 8470, loss = 0.305927, w = 0.334393, (0.68)\n",
      "epoch: 8480, loss = 0.305519, w = 0.334311, (0.68)\n",
      "epoch: 8490, loss = 0.307070, w = 0.334946, (0.66)\n",
      "epoch: 8500, loss = 0.306082, w = 0.333714, (0.68)\n",
      "epoch: 8510, loss = 0.305237, w = 0.332446, (0.67)\n",
      "epoch: 8520, loss = 0.295776, w = 0.325389, (0.68)\n",
      "epoch: 8530, loss = 0.306866, w = 0.333377, (0.69)\n",
      "epoch: 8540, loss = 0.306085, w = 0.332565, (0.66)\n",
      "epoch: 8550, loss = 0.303809, w = 0.330443, (0.67)\n",
      "ckpt 8550 saved with loss 0.303809\n",
      "epoch: 8560, loss = 0.308104, w = 0.333963, (0.68)\n",
      "epoch: 8570, loss = 0.305342, w = 0.332236, (0.68)\n",
      "epoch: 8580, loss = 0.304936, w = 0.332255, (0.67)\n",
      "epoch: 8590, loss = 0.302830, w = 0.330173, (0.73)\n",
      "epoch: 8600, loss = 0.306056, w = 0.333262, (0.68)\n",
      "epoch: 8610, loss = 0.303042, w = 0.330493, (0.68)\n",
      "epoch: 8620, loss = 0.305638, w = 0.332819, (0.66)\n",
      "epoch: 8630, loss = 0.306013, w = 0.333120, (0.67)\n",
      "epoch: 8640, loss = 0.305095, w = 0.332083, (0.67)\n",
      "epoch: 8650, loss = 0.306908, w = 0.333149, (0.67)\n",
      "epoch: 8660, loss = 0.304090, w = 0.331306, (0.70)\n",
      "epoch: 8670, loss = 0.304047, w = 0.331737, (0.68)\n",
      "epoch: 8680, loss = 0.307622, w = 0.333505, (0.67)\n",
      "epoch: 8690, loss = 0.303901, w = 0.330716, (0.67)\n",
      "epoch: 8700, loss = 0.302824, w = 0.331142, (0.69)\n",
      "ckpt 8700 saved with loss 0.302824\n",
      "epoch: 8710, loss = 0.304284, w = 0.331703, (0.67)\n",
      "epoch: 8720, loss = 0.303271, w = 0.331065, (0.67)\n",
      "epoch: 8730, loss = 0.304553, w = 0.331129, (0.70)\n",
      "epoch: 8740, loss = 0.303911, w = 0.330684, (0.68)\n",
      "epoch: 8750, loss = 0.302286, w = 0.329599, (0.68)\n",
      "ckpt 8750 saved with loss 0.302286\n",
      "epoch: 8760, loss = 0.302569, w = 0.329783, (0.67)\n",
      "epoch: 8770, loss = 0.302348, w = 0.329679, (0.70)\n",
      "epoch: 8780, loss = 0.302808, w = 0.329947, (0.68)\n",
      "epoch: 8790, loss = 0.303052, w = 0.330362, (0.67)\n",
      "epoch: 8800, loss = 0.301755, w = 0.328609, (0.67)\n",
      "ckpt 8800 saved with loss 0.301755\n",
      "epoch: 8810, loss = 0.303466, w = 0.330334, (0.68)\n",
      "epoch: 8820, loss = 0.301274, w = 0.328188, (0.69)\n",
      "epoch: 8830, loss = 0.301040, w = 0.329699, (0.67)\n",
      "epoch: 8840, loss = 0.302445, w = 0.328874, (0.71)\n",
      "epoch: 8850, loss = 0.296909, w = 0.325738, (0.66)\n",
      "ckpt 8850 saved with loss 0.296909\n",
      "epoch: 8860, loss = 0.303631, w = 0.330783, (0.67)\n",
      "epoch: 8870, loss = 0.301434, w = 0.328606, (0.68)\n",
      "epoch: 8880, loss = 0.300454, w = 0.326875, (0.66)\n",
      "epoch: 8890, loss = 0.301503, w = 0.328281, (0.67)\n",
      "epoch: 8900, loss = 0.301461, w = 0.328231, (0.70)\n",
      "epoch: 8910, loss = 0.299857, w = 0.327165, (0.67)\n",
      "epoch: 8920, loss = 0.300155, w = 0.326200, (0.67)\n",
      "epoch: 8930, loss = 0.301637, w = 0.327919, (0.67)\n",
      "epoch: 8940, loss = 0.302494, w = 0.328611, (0.68)\n",
      "epoch: 8950, loss = 0.299346, w = 0.326035, (0.66)\n",
      "epoch: 8960, loss = 0.303231, w = 0.328904, (0.68)\n",
      "epoch: 8970, loss = 0.299581, w = 0.326369, (0.69)\n",
      "epoch: 8980, loss = 0.300405, w = 0.326715, (0.68)\n",
      "epoch: 8990, loss = 0.302488, w = 0.328098, (0.68)\n",
      "epoch: 9000, loss = 0.298701, w = 0.325513, (0.72)\n",
      "epoch: 9010, loss = 0.299559, w = 0.327211, (0.66)\n",
      "epoch: 9020, loss = 0.299937, w = 0.327074, (0.67)\n",
      "epoch: 9030, loss = 0.300586, w = 0.327464, (0.66)\n",
      "epoch: 9040, loss = 0.301967, w = 0.328983, (0.69)\n",
      "epoch: 9050, loss = 0.300753, w = 0.327470, (0.68)\n",
      "epoch: 9060, loss = 0.299076, w = 0.326034, (0.68)\n",
      "epoch: 9070, loss = 0.299105, w = 0.325965, (0.67)\n",
      "epoch: 9080, loss = 0.297836, w = 0.324631, (0.68)\n",
      "epoch: 9090, loss = 0.299889, w = 0.326332, (0.67)\n",
      "epoch: 9100, loss = 0.300259, w = 0.326745, (0.67)\n",
      "epoch: 9110, loss = 0.299064, w = 0.326783, (0.70)\n",
      "epoch: 9120, loss = 0.299442, w = 0.326102, (0.68)\n",
      "epoch: 9130, loss = 0.297816, w = 0.324613, (0.67)\n",
      "epoch: 9140, loss = 0.294783, w = 0.324044, (0.68)\n",
      "epoch: 9150, loss = 0.298733, w = 0.325255, (0.67)\n",
      "epoch: 9160, loss = 0.299442, w = 0.325424, (0.67)\n",
      "epoch: 9170, loss = 0.301138, w = 0.325785, (0.68)\n",
      "epoch: 9180, loss = 0.297474, w = 0.324856, (0.70)\n",
      "epoch: 9190, loss = 0.298325, w = 0.325254, (0.67)\n",
      "epoch: 9200, loss = 0.296472, w = 0.324215, (0.68)\n",
      "ckpt 9200 saved with loss 0.296472\n",
      "epoch: 9210, loss = 0.296656, w = 0.324057, (0.67)\n",
      "epoch: 9220, loss = 0.296845, w = 0.323470, (0.70)\n",
      "epoch: 9230, loss = 0.296072, w = 0.323136, (0.69)\n",
      "epoch: 9240, loss = 0.295651, w = 0.322864, (0.67)\n",
      "epoch: 9250, loss = 0.296752, w = 0.323739, (0.72)\n",
      "epoch: 9260, loss = 0.297478, w = 0.324082, (0.67)\n",
      "epoch: 9270, loss = 0.296585, w = 0.323556, (0.67)\n",
      "epoch: 9280, loss = 0.296983, w = 0.323694, (0.69)\n",
      "epoch: 9290, loss = 0.297389, w = 0.323734, (0.67)\n",
      "epoch: 9300, loss = 0.294250, w = 0.321127, (0.67)\n",
      "ckpt 9300 saved with loss 0.294250\n",
      "epoch: 9310, loss = 0.296498, w = 0.323108, (0.67)\n",
      "epoch: 9320, loss = 0.293958, w = 0.321105, (0.68)\n",
      "epoch: 9330, loss = 0.295720, w = 0.322012, (0.66)\n",
      "epoch: 9340, loss = 0.296406, w = 0.322249, (0.69)\n",
      "epoch: 9350, loss = 0.296290, w = 0.322569, (0.69)\n",
      "epoch: 9360, loss = 0.296866, w = 0.322929, (0.67)\n",
      "epoch: 9370, loss = 0.294389, w = 0.321589, (0.68)\n",
      "epoch: 9380, loss = 0.297358, w = 0.323484, (0.66)\n",
      "epoch: 9390, loss = 0.296769, w = 0.323441, (0.69)\n",
      "epoch: 9400, loss = 0.294750, w = 0.321220, (0.68)\n",
      "epoch: 9410, loss = 0.297369, w = 0.324402, (0.68)\n",
      "epoch: 9420, loss = 0.295544, w = 0.322952, (0.72)\n",
      "epoch: 9430, loss = 0.294627, w = 0.321405, (0.67)\n",
      "epoch: 9440, loss = 0.294817, w = 0.320863, (0.67)\n",
      "epoch: 9450, loss = 0.296026, w = 0.321966, (0.68)\n",
      "epoch: 9460, loss = 0.295575, w = 0.322511, (0.70)\n",
      "epoch: 9470, loss = 0.297134, w = 0.323156, (0.69)\n",
      "epoch: 9480, loss = 0.297435, w = 0.322890, (0.67)\n",
      "epoch: 9490, loss = 0.294376, w = 0.321773, (0.67)\n",
      "epoch: 9500, loss = 0.295855, w = 0.322266, (0.66)\n",
      "epoch: 9510, loss = 0.294266, w = 0.321962, (0.67)\n",
      "epoch: 9520, loss = 0.295147, w = 0.322045, (0.67)\n",
      "epoch: 9530, loss = 0.292664, w = 0.320195, (0.69)\n",
      "epoch: 9540, loss = 0.293196, w = 0.320219, (0.67)\n",
      "epoch: 9550, loss = 0.294793, w = 0.320758, (0.66)\n",
      "epoch: 9560, loss = 0.295747, w = 0.322106, (0.68)\n",
      "epoch: 9570, loss = 0.295390, w = 0.321486, (0.69)\n",
      "epoch: 9580, loss = 0.295392, w = 0.321458, (0.67)\n",
      "epoch: 9590, loss = 0.294702, w = 0.321881, (0.68)\n",
      "epoch: 9600, loss = 0.295981, w = 0.322661, (0.69)\n",
      "epoch: 9610, loss = 0.292935, w = 0.320282, (0.67)\n",
      "epoch: 9620, loss = 0.294657, w = 0.321587, (0.67)\n",
      "epoch: 9630, loss = 0.293924, w = 0.321505, (0.67)\n",
      "epoch: 9640, loss = 0.292173, w = 0.318702, (0.68)\n",
      "epoch: 9650, loss = 0.292850, w = 0.319120, (0.67)\n",
      "ckpt 9650 saved with loss 0.292850\n",
      "epoch: 9660, loss = 0.292014, w = 0.318596, (0.68)\n",
      "epoch: 9670, loss = 0.291942, w = 0.319214, (0.68)\n",
      "epoch: 9680, loss = 0.292837, w = 0.319439, (0.67)\n",
      "epoch: 9690, loss = 0.292504, w = 0.319861, (0.66)\n",
      "epoch: 9700, loss = 0.293653, w = 0.319731, (0.71)\n",
      "epoch: 9710, loss = 0.292645, w = 0.319249, (0.67)\n",
      "epoch: 9720, loss = 0.293557, w = 0.319871, (0.66)\n",
      "epoch: 9730, loss = 0.291702, w = 0.318825, (0.67)\n",
      "epoch: 9740, loss = 0.294161, w = 0.319995, (0.69)\n",
      "epoch: 9750, loss = 0.292140, w = 0.319016, (0.69)\n",
      "ckpt 9750 saved with loss 0.292140\n",
      "epoch: 9760, loss = 0.290257, w = 0.317811, (0.67)\n",
      "epoch: 9770, loss = 0.291549, w = 0.317620, (0.70)\n",
      "epoch: 9780, loss = 0.291211, w = 0.317927, (0.67)\n",
      "epoch: 9790, loss = 0.290747, w = 0.317082, (0.67)\n",
      "epoch: 9800, loss = 0.290831, w = 0.316906, (0.67)\n",
      "ckpt 9800 saved with loss 0.290831\n",
      "epoch: 9810, loss = 0.290841, w = 0.317601, (0.68)\n",
      "epoch: 9820, loss = 0.289999, w = 0.316922, (0.67)\n",
      "epoch: 9830, loss = 0.289716, w = 0.316210, (0.66)\n",
      "epoch: 9840, loss = 0.290537, w = 0.316538, (0.69)\n",
      "epoch: 9850, loss = 0.290463, w = 0.316754, (0.67)\n",
      "ckpt 9850 saved with loss 0.290463\n",
      "epoch: 9860, loss = 0.292578, w = 0.318023, (0.66)\n",
      "epoch: 9870, loss = 0.290940, w = 0.317601, (0.67)\n",
      "epoch: 9880, loss = 0.291494, w = 0.316925, (0.70)\n",
      "epoch: 9890, loss = 0.290941, w = 0.317674, (0.67)\n",
      "epoch: 9900, loss = 0.290461, w = 0.316914, (0.67)\n",
      "ckpt 9900 saved with loss 0.290461\n",
      "epoch: 9910, loss = 0.288670, w = 0.314570, (0.69)\n",
      "epoch: 9920, loss = 0.287374, w = 0.313654, (0.68)\n",
      "epoch: 9930, loss = 0.290429, w = 0.316122, (0.69)\n",
      "epoch: 9940, loss = 0.290172, w = 0.316166, (0.67)\n",
      "epoch: 9950, loss = 0.289548, w = 0.317204, (0.68)\n",
      "ckpt 9950 saved with loss 0.289548\n",
      "epoch: 9960, loss = 0.290366, w = 0.316410, (0.68)\n",
      "epoch: 9970, loss = 0.291738, w = 0.317619, (0.68)\n",
      "epoch: 9980, loss = 0.289476, w = 0.316371, (0.68)\n",
      "epoch: 9990, loss = 0.291190, w = 0.316554, (0.67)\n",
      "epoch: 10000, loss = 0.290350, w = 0.316412, (0.67)\n",
      "epoch: 10010, loss = 0.290704, w = 0.316532, (0.67)\n",
      "epoch: 10020, loss = 0.288638, w = 0.315436, (0.69)\n",
      "epoch: 10030, loss = 0.289277, w = 0.316140, (0.69)\n",
      "epoch: 10040, loss = 0.288934, w = 0.315178, (0.69)\n",
      "epoch: 10050, loss = 0.288312, w = 0.314639, (0.66)\n",
      "ckpt 10050 saved with loss 0.288312\n",
      "epoch: 10060, loss = 0.290059, w = 0.315994, (0.67)\n",
      "epoch: 10070, loss = 0.288263, w = 0.314338, (0.67)\n",
      "epoch: 10080, loss = 0.289699, w = 0.315622, (0.67)\n",
      "epoch: 10090, loss = 0.288930, w = 0.314654, (0.67)\n",
      "epoch: 10100, loss = 0.289222, w = 0.315228, (0.67)\n",
      "epoch: 10110, loss = 0.288974, w = 0.315621, (0.69)\n",
      "epoch: 10120, loss = 0.289246, w = 0.314917, (0.66)\n",
      "epoch: 10130, loss = 0.287621, w = 0.314300, (0.67)\n",
      "epoch: 10140, loss = 0.288865, w = 0.314415, (0.71)\n",
      "epoch: 10150, loss = 0.287379, w = 0.313485, (0.68)\n",
      "ckpt 10150 saved with loss 0.287379\n",
      "epoch: 10160, loss = 0.287576, w = 0.313309, (0.68)\n",
      "epoch: 10170, loss = 0.288408, w = 0.314276, (0.67)\n",
      "epoch: 10180, loss = 0.288774, w = 0.315319, (0.70)\n",
      "epoch: 10190, loss = 0.288303, w = 0.313476, (0.67)\n",
      "epoch: 10200, loss = 0.288956, w = 0.314707, (0.67)\n",
      "epoch: 10210, loss = 0.289223, w = 0.315189, (0.70)\n",
      "epoch: 10220, loss = 0.287811, w = 0.313843, (0.67)\n",
      "epoch: 10230, loss = 0.288807, w = 0.314961, (0.67)\n",
      "epoch: 10240, loss = 0.287725, w = 0.314430, (0.67)\n",
      "epoch: 10250, loss = 0.288015, w = 0.313623, (0.70)\n",
      "epoch: 10260, loss = 0.286489, w = 0.312373, (0.66)\n",
      "epoch: 10270, loss = 0.287077, w = 0.312955, (0.68)\n",
      "epoch: 10280, loss = 0.287469, w = 0.313105, (0.68)\n",
      "epoch: 10290, loss = 0.285887, w = 0.311421, (0.67)\n",
      "epoch: 10300, loss = 0.287757, w = 0.312313, (0.69)\n",
      "epoch: 10310, loss = 0.287808, w = 0.313081, (0.67)\n",
      "epoch: 10320, loss = 0.287110, w = 0.313396, (0.70)\n",
      "epoch: 10330, loss = 0.289029, w = 0.313960, (0.67)\n",
      "epoch: 10340, loss = 0.286733, w = 0.312768, (0.67)\n",
      "epoch: 10350, loss = 0.286815, w = 0.312372, (0.68)\n",
      "ckpt 10350 saved with loss 0.286815\n",
      "epoch: 10360, loss = 0.286862, w = 0.312701, (0.67)\n",
      "epoch: 10370, loss = 0.284819, w = 0.310632, (0.66)\n",
      "epoch: 10380, loss = 0.286833, w = 0.311512, (0.69)\n",
      "epoch: 10390, loss = 0.285918, w = 0.311155, (0.69)\n",
      "epoch: 10400, loss = 0.286706, w = 0.312369, (0.66)\n",
      "ckpt 10400 saved with loss 0.286706\n",
      "epoch: 10410, loss = 0.286632, w = 0.311669, (0.67)\n",
      "epoch: 10420, loss = 0.288089, w = 0.313486, (0.67)\n",
      "epoch: 10430, loss = 0.287194, w = 0.312480, (0.70)\n",
      "epoch: 10440, loss = 0.284156, w = 0.310632, (0.67)\n",
      "epoch: 10450, loss = 0.284780, w = 0.310497, (0.68)\n",
      "ckpt 10450 saved with loss 0.284780\n",
      "epoch: 10460, loss = 0.286335, w = 0.311491, (0.68)\n",
      "epoch: 10470, loss = 0.286067, w = 0.311798, (0.66)\n",
      "epoch: 10480, loss = 0.284962, w = 0.311002, (0.68)\n",
      "epoch: 10490, loss = 0.285952, w = 0.311611, (0.67)\n",
      "epoch: 10500, loss = 0.285006, w = 0.310556, (0.70)\n",
      "epoch: 10510, loss = 0.284934, w = 0.310664, (0.66)\n",
      "epoch: 10520, loss = 0.284904, w = 0.309761, (0.67)\n",
      "epoch: 10530, loss = 0.283387, w = 0.309732, (0.67)\n",
      "epoch: 10540, loss = 0.283129, w = 0.309199, (0.69)\n",
      "epoch: 10550, loss = 0.285287, w = 0.310610, (0.66)\n",
      "epoch: 10560, loss = 0.284147, w = 0.309537, (0.69)\n",
      "epoch: 10570, loss = 0.283303, w = 0.308981, (0.66)\n",
      "epoch: 10580, loss = 0.285245, w = 0.311282, (0.66)\n",
      "epoch: 10590, loss = 0.285217, w = 0.309868, (0.69)\n",
      "epoch: 10600, loss = 0.283775, w = 0.309034, (0.67)\n",
      "ckpt 10600 saved with loss 0.283775\n",
      "epoch: 10610, loss = 0.285455, w = 0.310609, (0.71)\n",
      "epoch: 10620, loss = 0.286579, w = 0.311548, (0.67)\n",
      "epoch: 10630, loss = 0.283659, w = 0.309958, (0.69)\n",
      "epoch: 10640, loss = 0.282939, w = 0.309698, (0.66)\n",
      "epoch: 10650, loss = 0.284658, w = 0.310061, (0.67)\n",
      "epoch: 10660, loss = 0.283992, w = 0.310147, (0.67)\n",
      "epoch: 10670, loss = 0.284899, w = 0.309853, (0.67)\n",
      "epoch: 10680, loss = 0.283511, w = 0.308415, (0.68)\n",
      "epoch: 10690, loss = 0.282092, w = 0.308694, (0.66)\n",
      "epoch: 10700, loss = 0.284953, w = 0.310010, (0.70)\n",
      "epoch: 10710, loss = 0.283424, w = 0.308657, (0.66)\n",
      "epoch: 10720, loss = 0.283801, w = 0.308916, (0.67)\n",
      "epoch: 10730, loss = 0.283304, w = 0.308170, (0.67)\n",
      "epoch: 10740, loss = 0.281739, w = 0.307038, (0.67)\n",
      "epoch: 10750, loss = 0.281962, w = 0.307349, (0.67)\n",
      "ckpt 10750 saved with loss 0.281962\n",
      "epoch: 10760, loss = 0.283956, w = 0.308520, (0.67)\n",
      "epoch: 10770, loss = 0.282963, w = 0.308946, (0.71)\n",
      "epoch: 10780, loss = 0.282413, w = 0.307912, (0.66)\n",
      "epoch: 10790, loss = 0.282125, w = 0.308679, (0.67)\n",
      "epoch: 10800, loss = 0.283462, w = 0.308167, (0.67)\n",
      "epoch: 10810, loss = 0.284354, w = 0.308848, (0.67)\n",
      "epoch: 10820, loss = 0.280211, w = 0.305234, (0.67)\n",
      "epoch: 10830, loss = 0.281268, w = 0.307473, (0.68)\n",
      "epoch: 10840, loss = 0.281905, w = 0.307480, (0.70)\n",
      "epoch: 10850, loss = 0.280040, w = 0.306006, (0.67)\n",
      "ckpt 10850 saved with loss 0.280040\n",
      "epoch: 10860, loss = 0.281657, w = 0.307345, (0.67)\n",
      "epoch: 10870, loss = 0.279810, w = 0.304726, (0.68)\n",
      "epoch: 10880, loss = 0.281150, w = 0.306240, (0.68)\n",
      "epoch: 10890, loss = 0.280862, w = 0.307127, (0.67)\n",
      "epoch: 10900, loss = 0.280387, w = 0.306430, (0.67)\n",
      "epoch: 10910, loss = 0.280329, w = 0.306116, (0.68)\n",
      "epoch: 10920, loss = 0.280966, w = 0.306145, (0.67)\n",
      "epoch: 10930, loss = 0.282965, w = 0.308372, (0.67)\n",
      "epoch: 10940, loss = 0.282394, w = 0.307703, (0.67)\n",
      "epoch: 10950, loss = 0.281237, w = 0.307291, (0.67)\n",
      "epoch: 10960, loss = 0.281689, w = 0.306622, (0.67)\n",
      "epoch: 10970, loss = 0.280891, w = 0.306311, (0.69)\n",
      "epoch: 10980, loss = 0.279797, w = 0.305046, (0.66)\n",
      "epoch: 10990, loss = 0.279636, w = 0.304278, (0.67)\n",
      "epoch: 11000, loss = 0.279020, w = 0.304159, (0.69)\n",
      "ckpt 11000 saved with loss 0.279020\n",
      "epoch: 11010, loss = 0.278306, w = 0.303933, (0.67)\n",
      "epoch: 11020, loss = 0.278651, w = 0.303733, (0.67)\n",
      "epoch: 11030, loss = 0.277957, w = 0.302941, (0.68)\n",
      "epoch: 11040, loss = 0.279472, w = 0.304624, (0.73)\n",
      "epoch: 11050, loss = 0.279303, w = 0.304549, (0.66)\n",
      "epoch: 11060, loss = 0.277479, w = 0.302611, (0.67)\n",
      "epoch: 11070, loss = 0.279528, w = 0.304288, (0.68)\n",
      "epoch: 11080, loss = 0.278918, w = 0.303768, (0.67)\n",
      "epoch: 11090, loss = 0.278881, w = 0.303736, (0.67)\n",
      "epoch: 11100, loss = 0.279195, w = 0.304424, (0.67)\n",
      "epoch: 11110, loss = 0.277966, w = 0.303255, (0.70)\n",
      "epoch: 11120, loss = 0.277297, w = 0.302349, (0.66)\n",
      "epoch: 11130, loss = 0.278609, w = 0.302796, (0.67)\n",
      "epoch: 11140, loss = 0.276791, w = 0.303084, (0.67)\n",
      "epoch: 11150, loss = 0.279618, w = 0.304298, (0.67)\n",
      "epoch: 11160, loss = 0.276585, w = 0.301908, (0.67)\n",
      "epoch: 11170, loss = 0.278486, w = 0.304178, (0.67)\n",
      "epoch: 11180, loss = 0.278939, w = 0.304018, (0.66)\n",
      "epoch: 11190, loss = 0.278135, w = 0.303036, (0.66)\n",
      "epoch: 11200, loss = 0.276749, w = 0.302439, (0.69)\n",
      "ckpt 11200 saved with loss 0.276749\n",
      "epoch: 11210, loss = 0.278797, w = 0.303885, (0.66)\n",
      "epoch: 11220, loss = 0.278889, w = 0.303529, (0.69)\n",
      "epoch: 11230, loss = 0.278797, w = 0.303338, (0.67)\n",
      "epoch: 11240, loss = 0.276770, w = 0.302225, (0.66)\n",
      "epoch: 11250, loss = 0.277471, w = 0.302641, (0.67)\n",
      "epoch: 11260, loss = 0.279125, w = 0.304047, (0.67)\n",
      "epoch: 11270, loss = 0.276070, w = 0.302111, (0.66)\n",
      "epoch: 11280, loss = 0.276166, w = 0.302069, (0.66)\n",
      "epoch: 11290, loss = 0.276279, w = 0.300420, (0.67)\n",
      "epoch: 11300, loss = 0.277049, w = 0.302728, (0.66)\n",
      "epoch: 11310, loss = 0.278816, w = 0.303371, (0.68)\n",
      "epoch: 11320, loss = 0.277401, w = 0.302660, (0.67)\n",
      "epoch: 11330, loss = 0.277153, w = 0.302272, (0.66)\n",
      "epoch: 11340, loss = 0.279181, w = 0.302843, (0.66)\n",
      "epoch: 11350, loss = 0.277438, w = 0.302573, (0.67)\n",
      "epoch: 11360, loss = 0.276120, w = 0.301129, (0.67)\n",
      "epoch: 11370, loss = 0.276757, w = 0.301364, (0.66)\n",
      "epoch: 11380, loss = 0.277971, w = 0.302753, (0.67)\n",
      "epoch: 11390, loss = 0.277626, w = 0.302430, (0.66)\n",
      "epoch: 11400, loss = 0.276569, w = 0.302009, (0.68)\n",
      "ckpt 11400 saved with loss 0.276569\n",
      "epoch: 11410, loss = 0.276986, w = 0.301893, (0.67)\n",
      "epoch: 11420, loss = 0.276780, w = 0.301569, (0.67)\n",
      "epoch: 11430, loss = 0.274922, w = 0.299623, (0.67)\n",
      "epoch: 11440, loss = 0.276673, w = 0.301726, (0.67)\n",
      "epoch: 11450, loss = 0.273839, w = 0.299361, (0.66)\n",
      "ckpt 11450 saved with loss 0.273839\n",
      "epoch: 11460, loss = 0.276273, w = 0.301268, (0.66)\n",
      "epoch: 11470, loss = 0.276039, w = 0.300500, (0.67)\n",
      "epoch: 11480, loss = 0.276359, w = 0.301618, (0.66)\n",
      "epoch: 11490, loss = 0.274767, w = 0.299551, (0.67)\n",
      "epoch: 11500, loss = 0.273786, w = 0.299843, (0.66)\n",
      "ckpt 11500 saved with loss 0.273786\n",
      "epoch: 11510, loss = 0.275656, w = 0.300880, (0.66)\n",
      "epoch: 11520, loss = 0.276039, w = 0.300401, (0.66)\n",
      "epoch: 11530, loss = 0.273514, w = 0.299692, (0.67)\n",
      "epoch: 11540, loss = 0.273961, w = 0.300297, (0.66)\n",
      "epoch: 11550, loss = 0.274765, w = 0.300259, (0.66)\n",
      "epoch: 11560, loss = 0.274859, w = 0.299929, (0.67)\n",
      "epoch: 11570, loss = 0.276118, w = 0.301002, (0.66)\n",
      "epoch: 11580, loss = 0.275409, w = 0.299777, (0.68)\n",
      "epoch: 11590, loss = 0.276262, w = 0.300425, (0.66)\n",
      "epoch: 11600, loss = 0.276845, w = 0.301653, (0.66)\n",
      "epoch: 11610, loss = 0.275609, w = 0.300478, (0.67)\n",
      "epoch: 11620, loss = 0.276365, w = 0.301509, (0.66)\n",
      "epoch: 11630, loss = 0.273938, w = 0.299599, (0.66)\n",
      "epoch: 11640, loss = 0.276168, w = 0.300980, (0.66)\n",
      "epoch: 11650, loss = 0.275731, w = 0.300363, (0.67)\n",
      "epoch: 11660, loss = 0.273923, w = 0.299050, (0.66)\n",
      "epoch: 11670, loss = 0.273504, w = 0.298337, (0.66)\n",
      "epoch: 11680, loss = 0.272969, w = 0.296918, (0.67)\n",
      "epoch: 11690, loss = 0.273820, w = 0.298683, (0.68)\n",
      "epoch: 11700, loss = 0.273999, w = 0.298556, (0.66)\n",
      "epoch: 11710, loss = 0.274155, w = 0.298074, (0.66)\n",
      "epoch: 11720, loss = 0.272869, w = 0.298174, (0.66)\n",
      "epoch: 11730, loss = 0.274366, w = 0.298733, (0.67)\n",
      "epoch: 11740, loss = 0.273285, w = 0.298675, (0.66)\n",
      "epoch: 11750, loss = 0.273615, w = 0.298090, (0.66)\n",
      "ckpt 11750 saved with loss 0.273615\n",
      "epoch: 11760, loss = 0.273197, w = 0.297493, (0.67)\n",
      "epoch: 11770, loss = 0.274637, w = 0.297916, (0.67)\n",
      "epoch: 11780, loss = 0.273416, w = 0.297644, (0.66)\n",
      "epoch: 11790, loss = 0.272055, w = 0.297088, (0.66)\n",
      "epoch: 11800, loss = 0.272242, w = 0.297122, (0.67)\n",
      "ckpt 11800 saved with loss 0.272242\n",
      "epoch: 11810, loss = 0.272138, w = 0.296580, (0.68)\n",
      "epoch: 11820, loss = 0.272177, w = 0.296574, (0.68)\n",
      "epoch: 11830, loss = 0.273083, w = 0.298489, (0.67)\n",
      "epoch: 11840, loss = 0.271811, w = 0.296490, (0.66)\n",
      "epoch: 11850, loss = 0.270104, w = 0.295164, (0.69)\n",
      "ckpt 11850 saved with loss 0.270104\n",
      "epoch: 11860, loss = 0.272846, w = 0.297113, (0.66)\n",
      "epoch: 11870, loss = 0.272244, w = 0.296984, (0.69)\n",
      "epoch: 11880, loss = 0.271936, w = 0.296470, (0.66)\n",
      "epoch: 11890, loss = 0.271175, w = 0.296231, (0.67)\n",
      "epoch: 11900, loss = 0.273009, w = 0.297812, (0.66)\n",
      "epoch: 11910, loss = 0.273001, w = 0.297321, (0.66)\n",
      "epoch: 11920, loss = 0.269714, w = 0.295683, (0.66)\n",
      "epoch: 11930, loss = 0.272192, w = 0.296384, (0.67)\n",
      "epoch: 11940, loss = 0.272060, w = 0.297023, (0.67)\n",
      "epoch: 11950, loss = 0.271502, w = 0.295833, (0.66)\n",
      "epoch: 11960, loss = 0.273114, w = 0.297454, (0.67)\n",
      "epoch: 11970, loss = 0.271658, w = 0.297377, (0.66)\n",
      "epoch: 11980, loss = 0.273637, w = 0.298238, (0.67)\n",
      "epoch: 11990, loss = 0.270634, w = 0.295979, (0.66)\n",
      "epoch: 12000, loss = 0.270744, w = 0.295299, (0.67)\n",
      "epoch: 12010, loss = 0.270435, w = 0.295012, (0.67)\n",
      "epoch: 12020, loss = 0.270851, w = 0.296170, (0.66)\n",
      "epoch: 12030, loss = 0.269435, w = 0.294393, (0.67)\n",
      "epoch: 12040, loss = 0.269388, w = 0.294178, (0.67)\n",
      "epoch: 12050, loss = 0.270573, w = 0.295546, (0.68)\n",
      "epoch: 12060, loss = 0.271036, w = 0.295865, (0.67)\n",
      "epoch: 12070, loss = 0.269544, w = 0.294832, (0.69)\n",
      "epoch: 12080, loss = 0.268772, w = 0.293672, (0.66)\n",
      "epoch: 12090, loss = 0.270646, w = 0.294052, (0.66)\n",
      "epoch: 12100, loss = 0.268647, w = 0.294033, (0.67)\n",
      "ckpt 12100 saved with loss 0.268647\n",
      "epoch: 12110, loss = 0.268234, w = 0.293035, (0.67)\n",
      "epoch: 12120, loss = 0.269977, w = 0.294501, (0.66)\n",
      "epoch: 12130, loss = 0.270721, w = 0.295800, (0.66)\n",
      "epoch: 12140, loss = 0.268862, w = 0.292970, (0.68)\n",
      "epoch: 12150, loss = 0.271083, w = 0.294560, (0.67)\n",
      "epoch: 12160, loss = 0.270379, w = 0.294271, (0.68)\n",
      "epoch: 12170, loss = 0.267957, w = 0.293094, (0.67)\n",
      "epoch: 12180, loss = 0.269396, w = 0.293895, (0.66)\n",
      "epoch: 12190, loss = 0.269500, w = 0.293341, (0.66)\n",
      "epoch: 12200, loss = 0.267648, w = 0.292567, (0.67)\n",
      "ckpt 12200 saved with loss 0.267648\n",
      "epoch: 12210, loss = 0.269808, w = 0.294139, (0.66)\n",
      "epoch: 12220, loss = 0.269554, w = 0.294251, (0.67)\n",
      "epoch: 12230, loss = 0.267751, w = 0.292399, (0.66)\n",
      "epoch: 12240, loss = 0.267909, w = 0.292556, (0.66)\n",
      "epoch: 12250, loss = 0.268924, w = 0.293953, (0.67)\n",
      "epoch: 12260, loss = 0.268283, w = 0.292787, (0.66)\n",
      "epoch: 12270, loss = 0.268179, w = 0.292793, (0.67)\n",
      "epoch: 12280, loss = 0.267209, w = 0.292186, (0.66)\n",
      "epoch: 12290, loss = 0.266983, w = 0.291468, (0.67)\n",
      "epoch: 12300, loss = 0.267817, w = 0.292587, (0.67)\n",
      "epoch: 12310, loss = 0.267034, w = 0.292653, (0.69)\n",
      "epoch: 12320, loss = 0.268188, w = 0.291962, (0.67)\n",
      "epoch: 12330, loss = 0.267780, w = 0.292096, (0.67)\n",
      "epoch: 12340, loss = 0.265821, w = 0.291673, (0.68)\n",
      "epoch: 12350, loss = 0.267432, w = 0.292378, (0.66)\n",
      "ckpt 12350 saved with loss 0.267432\n",
      "epoch: 12360, loss = 0.268395, w = 0.292554, (0.67)\n",
      "epoch: 12370, loss = 0.266598, w = 0.290758, (0.66)\n",
      "epoch: 12380, loss = 0.267295, w = 0.292073, (0.67)\n",
      "epoch: 12390, loss = 0.265793, w = 0.290597, (0.67)\n",
      "epoch: 12400, loss = 0.266192, w = 0.290507, (0.67)\n",
      "ckpt 12400 saved with loss 0.266192\n",
      "epoch: 12410, loss = 0.267106, w = 0.290740, (0.67)\n",
      "epoch: 12420, loss = 0.267009, w = 0.291647, (0.66)\n",
      "epoch: 12430, loss = 0.267945, w = 0.291283, (0.67)\n",
      "epoch: 12440, loss = 0.268345, w = 0.292539, (0.67)\n",
      "epoch: 12450, loss = 0.266190, w = 0.291045, (0.67)\n",
      "ckpt 12450 saved with loss 0.266190\n",
      "epoch: 12460, loss = 0.268529, w = 0.292703, (0.67)\n",
      "epoch: 12470, loss = 0.267028, w = 0.291691, (0.66)\n",
      "epoch: 12480, loss = 0.264504, w = 0.289406, (0.67)\n",
      "epoch: 12490, loss = 0.267290, w = 0.291091, (0.67)\n",
      "epoch: 12500, loss = 0.264540, w = 0.290827, (0.66)\n",
      "ckpt 12500 saved with loss 0.264540\n",
      "epoch: 12510, loss = 0.265691, w = 0.289610, (0.67)\n",
      "epoch: 12520, loss = 0.266626, w = 0.291642, (0.67)\n",
      "epoch: 12530, loss = 0.265949, w = 0.290681, (0.67)\n",
      "epoch: 12540, loss = 0.265222, w = 0.289962, (0.67)\n",
      "epoch: 12550, loss = 0.266461, w = 0.290981, (0.68)\n",
      "epoch: 12560, loss = 0.266245, w = 0.290775, (0.68)\n",
      "epoch: 12570, loss = 0.264849, w = 0.290170, (0.68)\n",
      "epoch: 12580, loss = 0.265184, w = 0.290375, (0.67)\n",
      "epoch: 12590, loss = 0.265787, w = 0.290062, (0.68)\n",
      "epoch: 12600, loss = 0.267104, w = 0.291793, (0.66)\n",
      "epoch: 12610, loss = 0.265063, w = 0.289344, (0.68)\n",
      "epoch: 12620, loss = 0.263559, w = 0.288759, (0.68)\n",
      "epoch: 12630, loss = 0.263379, w = 0.288247, (0.67)\n",
      "epoch: 12640, loss = 0.260019, w = 0.286070, (0.66)\n",
      "epoch: 12650, loss = 0.265167, w = 0.289294, (0.68)\n",
      "epoch: 12660, loss = 0.263710, w = 0.288852, (0.66)\n",
      "epoch: 12670, loss = 0.265912, w = 0.289984, (0.66)\n",
      "epoch: 12680, loss = 0.264788, w = 0.288565, (0.67)\n",
      "epoch: 12690, loss = 0.263853, w = 0.288502, (0.67)\n",
      "epoch: 12700, loss = 0.264466, w = 0.289140, (0.66)\n",
      "ckpt 12700 saved with loss 0.264466\n",
      "epoch: 12710, loss = 0.265612, w = 0.289350, (0.67)\n",
      "epoch: 12720, loss = 0.264394, w = 0.288337, (0.68)\n",
      "epoch: 12730, loss = 0.264724, w = 0.288917, (0.67)\n",
      "epoch: 12740, loss = 0.264717, w = 0.289082, (0.67)\n",
      "epoch: 12750, loss = 0.263835, w = 0.287673, (0.67)\n",
      "ckpt 12750 saved with loss 0.263835\n",
      "epoch: 12760, loss = 0.266013, w = 0.291019, (0.66)\n",
      "epoch: 12770, loss = 0.264631, w = 0.288488, (0.66)\n",
      "epoch: 12780, loss = 0.265083, w = 0.288619, (0.67)\n",
      "epoch: 12790, loss = 0.262490, w = 0.286005, (0.66)\n",
      "epoch: 12800, loss = 0.263415, w = 0.286987, (0.68)\n",
      "ckpt 12800 saved with loss 0.263415\n",
      "epoch: 12810, loss = 0.262868, w = 0.286653, (0.67)\n",
      "epoch: 12820, loss = 0.262816, w = 0.287022, (0.66)\n",
      "epoch: 12830, loss = 0.264038, w = 0.287543, (0.68)\n",
      "epoch: 12840, loss = 0.263003, w = 0.287742, (0.67)\n",
      "epoch: 12850, loss = 0.263789, w = 0.288120, (0.67)\n",
      "epoch: 12860, loss = 0.262289, w = 0.286504, (0.67)\n",
      "epoch: 12870, loss = 0.262554, w = 0.287068, (0.67)\n",
      "epoch: 12880, loss = 0.262458, w = 0.286421, (0.66)\n",
      "epoch: 12890, loss = 0.263826, w = 0.287667, (0.66)\n",
      "epoch: 12900, loss = 0.261564, w = 0.285879, (0.67)\n",
      "ckpt 12900 saved with loss 0.261564\n",
      "epoch: 12910, loss = 0.262168, w = 0.285966, (0.67)\n",
      "epoch: 12920, loss = 0.263340, w = 0.287683, (0.67)\n",
      "epoch: 12930, loss = 0.261822, w = 0.286463, (0.67)\n",
      "epoch: 12940, loss = 0.261174, w = 0.286016, (0.67)\n",
      "epoch: 12950, loss = 0.263459, w = 0.287003, (0.67)\n",
      "epoch: 12960, loss = 0.262607, w = 0.286025, (0.67)\n",
      "epoch: 12970, loss = 0.263221, w = 0.287012, (0.67)\n",
      "epoch: 12980, loss = 0.261391, w = 0.285932, (0.66)\n",
      "epoch: 12990, loss = 0.261379, w = 0.285772, (0.67)\n",
      "epoch: 13000, loss = 0.262339, w = 0.286946, (0.67)\n",
      "epoch: 13010, loss = 0.262410, w = 0.286522, (0.67)\n",
      "epoch: 13020, loss = 0.260766, w = 0.285122, (0.67)\n",
      "epoch: 13030, loss = 0.262006, w = 0.285760, (0.68)\n",
      "epoch: 13040, loss = 0.263024, w = 0.287314, (0.66)\n",
      "epoch: 13050, loss = 0.263113, w = 0.287186, (0.67)\n",
      "epoch: 13060, loss = 0.262825, w = 0.287528, (0.66)\n",
      "epoch: 13070, loss = 0.261972, w = 0.286291, (0.67)\n",
      "epoch: 13080, loss = 0.262811, w = 0.286712, (0.67)\n",
      "epoch: 13090, loss = 0.262045, w = 0.285231, (0.66)\n",
      "epoch: 13100, loss = 0.262170, w = 0.285882, (0.68)\n",
      "epoch: 13110, loss = 0.261579, w = 0.285211, (0.66)\n",
      "epoch: 13120, loss = 0.262179, w = 0.285818, (0.67)\n",
      "epoch: 13130, loss = 0.261307, w = 0.285526, (0.67)\n",
      "epoch: 13140, loss = 0.262775, w = 0.286376, (0.66)\n",
      "epoch: 13150, loss = 0.261175, w = 0.285130, (0.67)\n",
      "ckpt 13150 saved with loss 0.261175\n",
      "epoch: 13160, loss = 0.260218, w = 0.284240, (0.67)\n",
      "epoch: 13170, loss = 0.261311, w = 0.285309, (0.67)\n",
      "epoch: 13180, loss = 0.261412, w = 0.285481, (0.67)\n",
      "epoch: 13190, loss = 0.260439, w = 0.283959, (0.68)\n",
      "epoch: 13200, loss = 0.262859, w = 0.286074, (0.69)\n",
      "epoch: 13210, loss = 0.261944, w = 0.285936, (0.69)\n",
      "epoch: 13220, loss = 0.261591, w = 0.285204, (0.66)\n",
      "epoch: 13230, loss = 0.261765, w = 0.285685, (0.67)\n",
      "epoch: 13240, loss = 0.257368, w = 0.282197, (0.67)\n",
      "epoch: 13250, loss = 0.260970, w = 0.284685, (0.66)\n",
      "ckpt 13250 saved with loss 0.260970\n",
      "epoch: 13260, loss = 0.260152, w = 0.284558, (0.66)\n",
      "epoch: 13270, loss = 0.260954, w = 0.285300, (0.66)\n",
      "epoch: 13280, loss = 0.261788, w = 0.285584, (0.67)\n",
      "epoch: 13290, loss = 0.259214, w = 0.283034, (0.66)\n",
      "epoch: 13300, loss = 0.259023, w = 0.282290, (0.67)\n",
      "ckpt 13300 saved with loss 0.259023\n",
      "epoch: 13310, loss = 0.260083, w = 0.284451, (0.66)\n",
      "epoch: 13320, loss = 0.260684, w = 0.284226, (0.66)\n",
      "epoch: 13330, loss = 0.258775, w = 0.282976, (0.66)\n",
      "epoch: 13340, loss = 0.259576, w = 0.283048, (0.67)\n",
      "epoch: 13350, loss = 0.259600, w = 0.283798, (0.68)\n",
      "epoch: 13360, loss = 0.259428, w = 0.283693, (0.67)\n",
      "epoch: 13370, loss = 0.258265, w = 0.283035, (0.67)\n",
      "epoch: 13380, loss = 0.259562, w = 0.283677, (0.66)\n",
      "epoch: 13390, loss = 0.260445, w = 0.283983, (0.68)\n",
      "epoch: 13400, loss = 0.260201, w = 0.283423, (0.66)\n",
      "epoch: 13410, loss = 0.259634, w = 0.283332, (0.67)\n",
      "epoch: 13420, loss = 0.261563, w = 0.285118, (0.69)\n",
      "epoch: 13430, loss = 0.259284, w = 0.283413, (0.67)\n",
      "epoch: 13440, loss = 0.258321, w = 0.282364, (0.66)\n",
      "epoch: 13450, loss = 0.259328, w = 0.283855, (0.67)\n",
      "epoch: 13460, loss = 0.258911, w = 0.282689, (0.66)\n",
      "epoch: 13470, loss = 0.258062, w = 0.282126, (0.67)\n",
      "epoch: 13480, loss = 0.258763, w = 0.281920, (0.68)\n",
      "epoch: 13490, loss = 0.260560, w = 0.283559, (0.66)\n",
      "epoch: 13500, loss = 0.258423, w = 0.282287, (0.67)\n",
      "ckpt 13500 saved with loss 0.258423\n",
      "epoch: 13510, loss = 0.259369, w = 0.282785, (0.66)\n",
      "epoch: 13520, loss = 0.258277, w = 0.282053, (0.68)\n",
      "epoch: 13530, loss = 0.257905, w = 0.280999, (0.67)\n",
      "epoch: 13540, loss = 0.257672, w = 0.281726, (0.66)\n",
      "epoch: 13550, loss = 0.257917, w = 0.281835, (0.66)\n",
      "ckpt 13550 saved with loss 0.257917\n",
      "epoch: 13560, loss = 0.255831, w = 0.280579, (0.66)\n",
      "epoch: 13570, loss = 0.257753, w = 0.281251, (0.67)\n",
      "epoch: 13580, loss = 0.256583, w = 0.281025, (0.67)\n",
      "epoch: 13590, loss = 0.258085, w = 0.281101, (0.67)\n",
      "epoch: 13600, loss = 0.259142, w = 0.283264, (0.66)\n",
      "epoch: 13610, loss = 0.259647, w = 0.282944, (0.66)\n",
      "epoch: 13620, loss = 0.257091, w = 0.280649, (0.66)\n",
      "epoch: 13630, loss = 0.175362, w = 0.225530, (0.68)\n",
      "epoch: 13640, loss = 0.249791, w = 0.272897, (0.67)\n",
      "epoch: 13650, loss = 0.253303, w = 0.277423, (0.67)\n",
      "ckpt 13650 saved with loss 0.253303\n",
      "epoch: 13660, loss = 0.255855, w = 0.279253, (0.67)\n",
      "epoch: 13670, loss = 0.257339, w = 0.280459, (0.66)\n",
      "epoch: 13680, loss = 0.255884, w = 0.278774, (0.67)\n",
      "epoch: 13690, loss = 0.256682, w = 0.279807, (0.66)\n",
      "epoch: 13700, loss = 0.255113, w = 0.280181, (0.66)\n",
      "epoch: 13710, loss = 0.255366, w = 0.278579, (0.67)\n",
      "epoch: 13720, loss = 0.255954, w = 0.279213, (0.66)\n",
      "epoch: 13730, loss = 0.256734, w = 0.280530, (0.66)\n",
      "epoch: 13740, loss = 0.257152, w = 0.280427, (0.66)\n",
      "epoch: 13750, loss = 0.256914, w = 0.281311, (0.66)\n",
      "epoch: 13760, loss = 0.255377, w = 0.279362, (0.67)\n",
      "epoch: 13770, loss = 0.254119, w = 0.277656, (0.68)\n",
      "epoch: 13780, loss = 0.257612, w = 0.281550, (0.67)\n",
      "epoch: 13790, loss = 0.252654, w = 0.276751, (0.67)\n",
      "epoch: 13800, loss = 0.256248, w = 0.279705, (0.66)\n",
      "epoch: 13810, loss = 0.253942, w = 0.277914, (0.67)\n",
      "epoch: 13820, loss = 0.255171, w = 0.278224, (0.67)\n",
      "epoch: 13830, loss = 0.256139, w = 0.279711, (0.67)\n",
      "epoch: 13840, loss = 0.254971, w = 0.278323, (0.67)\n",
      "epoch: 13850, loss = 0.255672, w = 0.279116, (0.66)\n",
      "epoch: 13860, loss = 0.257070, w = 0.279898, (0.69)\n",
      "epoch: 13870, loss = 0.256025, w = 0.279603, (0.66)\n",
      "epoch: 13880, loss = 0.255445, w = 0.279758, (0.67)\n",
      "epoch: 13890, loss = 0.253915, w = 0.278219, (0.68)\n",
      "epoch: 13900, loss = 0.252061, w = 0.276653, (0.66)\n",
      "ckpt 13900 saved with loss 0.252061\n",
      "epoch: 13910, loss = 0.253262, w = 0.277382, (0.66)\n",
      "epoch: 13920, loss = 0.256030, w = 0.279084, (0.67)\n",
      "epoch: 13930, loss = 0.254717, w = 0.278565, (0.67)\n",
      "epoch: 13940, loss = 0.254466, w = 0.278645, (0.66)\n",
      "epoch: 13950, loss = 0.255186, w = 0.279059, (0.66)\n",
      "epoch: 13960, loss = 0.255888, w = 0.280614, (0.66)\n",
      "epoch: 13970, loss = 0.255433, w = 0.279588, (0.66)\n",
      "epoch: 13980, loss = 0.254386, w = 0.278396, (0.67)\n",
      "epoch: 13990, loss = 0.254749, w = 0.278303, (0.66)\n",
      "epoch: 14000, loss = 0.255034, w = 0.278736, (0.67)\n",
      "epoch: 14010, loss = 0.253716, w = 0.277126, (0.67)\n",
      "epoch: 14020, loss = 0.254990, w = 0.278518, (0.67)\n",
      "epoch: 14030, loss = 0.255048, w = 0.278232, (0.66)\n",
      "epoch: 14040, loss = 0.254431, w = 0.277333, (0.67)\n",
      "epoch: 14050, loss = 0.254721, w = 0.278508, (0.66)\n",
      "epoch: 14060, loss = 0.253687, w = 0.278513, (0.66)\n",
      "epoch: 14070, loss = 0.253744, w = 0.277014, (0.66)\n",
      "epoch: 14080, loss = 0.254453, w = 0.278656, (0.68)\n",
      "epoch: 14090, loss = 0.253548, w = 0.276940, (0.67)\n",
      "epoch: 14100, loss = 0.252624, w = 0.276588, (0.66)\n",
      "epoch: 14110, loss = 0.253355, w = 0.277117, (0.66)\n",
      "epoch: 14120, loss = 0.252888, w = 0.277030, (0.66)\n",
      "epoch: 14130, loss = 0.252679, w = 0.276592, (0.67)\n",
      "epoch: 14140, loss = 0.254325, w = 0.277982, (0.67)\n",
      "epoch: 14150, loss = 0.253002, w = 0.276862, (0.70)\n",
      "epoch: 14160, loss = 0.255055, w = 0.278232, (0.67)\n",
      "epoch: 14170, loss = 0.253718, w = 0.278229, (0.68)\n",
      "epoch: 14180, loss = 0.253256, w = 0.277060, (0.66)\n",
      "epoch: 14190, loss = 0.254201, w = 0.278047, (0.66)\n",
      "epoch: 14200, loss = 0.253015, w = 0.277284, (0.67)\n",
      "epoch: 14210, loss = 0.251726, w = 0.276207, (0.66)\n",
      "epoch: 14220, loss = 0.253122, w = 0.276274, (0.66)\n",
      "epoch: 14230, loss = 0.252705, w = 0.276495, (0.66)\n",
      "epoch: 14240, loss = 0.254392, w = 0.277338, (0.67)\n",
      "epoch: 14250, loss = 0.252343, w = 0.276061, (0.66)\n",
      "epoch: 14260, loss = 0.251067, w = 0.274972, (0.67)\n",
      "epoch: 14270, loss = 0.250942, w = 0.274870, (0.66)\n",
      "epoch: 14280, loss = 0.252906, w = 0.276286, (0.67)\n",
      "epoch: 14290, loss = 0.251337, w = 0.275411, (0.67)\n",
      "epoch: 14300, loss = 0.251497, w = 0.275658, (0.66)\n",
      "ckpt 14300 saved with loss 0.251497\n",
      "epoch: 14310, loss = 0.250612, w = 0.273948, (0.66)\n",
      "epoch: 14320, loss = 0.251801, w = 0.276125, (0.66)\n",
      "epoch: 14330, loss = 0.250146, w = 0.273573, (0.66)\n",
      "epoch: 14340, loss = 0.253270, w = 0.276126, (0.66)\n",
      "epoch: 14350, loss = 0.252333, w = 0.276437, (0.66)\n",
      "epoch: 14360, loss = 0.252995, w = 0.276464, (0.66)\n",
      "epoch: 14370, loss = 0.251320, w = 0.274455, (0.68)\n",
      "epoch: 14380, loss = 0.252827, w = 0.276536, (0.66)\n",
      "epoch: 14390, loss = 0.250126, w = 0.273666, (0.66)\n",
      "epoch: 14400, loss = 0.250595, w = 0.274618, (0.66)\n",
      "ckpt 14400 saved with loss 0.250595\n",
      "epoch: 14410, loss = 0.250600, w = 0.274343, (0.66)\n",
      "epoch: 14420, loss = 0.250079, w = 0.273656, (0.66)\n",
      "epoch: 14430, loss = 0.250409, w = 0.274280, (0.67)\n",
      "epoch: 14440, loss = 0.251209, w = 0.274937, (0.67)\n",
      "epoch: 14450, loss = 0.250090, w = 0.274368, (0.66)\n",
      "ckpt 14450 saved with loss 0.250090\n",
      "epoch: 14460, loss = 0.252431, w = 0.276342, (0.68)\n",
      "epoch: 14470, loss = 0.251196, w = 0.274841, (0.67)\n",
      "epoch: 14480, loss = 0.250992, w = 0.274713, (0.67)\n",
      "epoch: 14490, loss = 0.249488, w = 0.272450, (0.67)\n",
      "epoch: 14500, loss = 0.250659, w = 0.274276, (0.68)\n",
      "epoch: 14510, loss = 0.250573, w = 0.274380, (0.66)\n",
      "epoch: 14520, loss = 0.250547, w = 0.274053, (0.67)\n",
      "epoch: 14530, loss = 0.251044, w = 0.273729, (0.67)\n",
      "epoch: 14540, loss = 0.252506, w = 0.275833, (0.67)\n",
      "epoch: 14550, loss = 0.251167, w = 0.274718, (0.67)\n",
      "epoch: 14560, loss = 0.249679, w = 0.272878, (0.67)\n",
      "epoch: 14570, loss = 0.249884, w = 0.273285, (0.67)\n",
      "epoch: 14580, loss = 0.250727, w = 0.273353, (0.66)\n",
      "epoch: 14590, loss = 0.250593, w = 0.273451, (0.66)\n",
      "epoch: 14600, loss = 0.248265, w = 0.271919, (0.66)\n",
      "ckpt 14600 saved with loss 0.248265\n",
      "epoch: 14610, loss = 0.249829, w = 0.273850, (0.66)\n",
      "epoch: 14620, loss = 0.250654, w = 0.273846, (0.67)\n",
      "epoch: 14630, loss = 0.248846, w = 0.272780, (0.66)\n",
      "epoch: 14640, loss = 0.247083, w = 0.271021, (0.67)\n",
      "epoch: 14650, loss = 0.249206, w = 0.272662, (0.66)\n",
      "epoch: 14660, loss = 0.249906, w = 0.273928, (0.67)\n",
      "epoch: 14670, loss = 0.250596, w = 0.273577, (0.66)\n",
      "epoch: 14680, loss = 0.248967, w = 0.273329, (0.67)\n",
      "epoch: 14690, loss = 0.248747, w = 0.272278, (0.66)\n",
      "epoch: 14700, loss = 0.249199, w = 0.272861, (0.66)\n",
      "epoch: 14710, loss = 0.248646, w = 0.273326, (0.67)\n",
      "epoch: 14720, loss = 0.248424, w = 0.271202, (0.66)\n",
      "epoch: 14730, loss = 0.249480, w = 0.272629, (0.66)\n",
      "epoch: 14740, loss = 0.249301, w = 0.272502, (0.67)\n",
      "epoch: 14750, loss = 0.248819, w = 0.272263, (0.67)\n",
      "epoch: 14760, loss = 0.249557, w = 0.272566, (0.67)\n",
      "epoch: 14770, loss = 0.247404, w = 0.270536, (0.66)\n",
      "epoch: 14780, loss = 0.249624, w = 0.272426, (0.67)\n",
      "epoch: 14790, loss = 0.250723, w = 0.274059, (0.68)\n",
      "epoch: 14800, loss = 0.249868, w = 0.272933, (0.66)\n",
      "epoch: 14810, loss = 0.247607, w = 0.271381, (0.66)\n",
      "epoch: 14820, loss = 0.247668, w = 0.271374, (0.67)\n",
      "epoch: 14830, loss = 0.248992, w = 0.272619, (0.66)\n",
      "epoch: 14840, loss = 0.248705, w = 0.272730, (0.68)\n",
      "epoch: 14850, loss = 0.248200, w = 0.271657, (0.67)\n",
      "ckpt 14850 saved with loss 0.248200\n",
      "epoch: 14860, loss = 0.247177, w = 0.270844, (0.68)\n",
      "epoch: 14870, loss = 0.245320, w = 0.270050, (0.66)\n",
      "epoch: 14880, loss = 0.247204, w = 0.271026, (0.66)\n",
      "epoch: 14890, loss = 0.248579, w = 0.272350, (0.66)\n",
      "epoch: 14900, loss = 0.245577, w = 0.270039, (0.66)\n",
      "ckpt 14900 saved with loss 0.245577\n",
      "epoch: 14910, loss = 0.247754, w = 0.270975, (0.67)\n",
      "epoch: 14920, loss = 0.246192, w = 0.269907, (0.66)\n",
      "epoch: 14930, loss = 0.247763, w = 0.270864, (0.68)\n",
      "epoch: 14940, loss = 0.247616, w = 0.270691, (0.66)\n",
      "epoch: 14950, loss = 0.247101, w = 0.270420, (0.67)\n",
      "epoch: 14960, loss = 0.248395, w = 0.271311, (0.66)\n",
      "epoch: 14970, loss = 0.248272, w = 0.270508, (0.67)\n",
      "epoch: 14980, loss = 0.245864, w = 0.269217, (0.66)\n",
      "epoch: 14990, loss = 0.247451, w = 0.271454, (0.66)\n"
     ]
    }
   ],
   "source": [
    "!python GAN_training.py --gpu_id 0 --model_id test2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
